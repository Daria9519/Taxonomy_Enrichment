{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_ = '../data/train.txt'\n",
    "test_path = '../data/dev.txt'\n",
    "label_path = '../data/label.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as train:\n",
    "        reader = csv.reader(train, delimiter=\"\\t\")\n",
    "        text_file = []\n",
    "        for line in reader:\n",
    "            text_file.append(line)\n",
    "    return text_file\n",
    "\n",
    "#Converting upload file into file with binary classification, where 1 - ISA relation, 0 - other relation\n",
    "\n",
    "def binary_convert(path):\n",
    "    txt_file = data_loader(path)\n",
    "    text_array = np.array(txt_file)\n",
    "\n",
    "    copy_arr = text_array\n",
    "    for row_idx in range(len(text_array)):\n",
    "        if text_array[row_idx][1] == 'ISA':\n",
    "              copy_arr[row_idx][1] = 1\n",
    "        elif text_array[row_idx][1] != 'ISA':\n",
    "              copy_arr[row_idx][1] = 0\n",
    "    print(f'Length of uploaded file:{len(copy_arr)}')\n",
    "    return copy_arr\n",
    "\n",
    "#We create two arrays ISA_example and Other_example for dividing the train file on train and evaluation sets\n",
    "\n",
    "def create_new_arrays(path):\n",
    "    binary_text = binary_convert(path)\n",
    "    ISA_example = []\n",
    "    Other_example = []\n",
    "    for line_idx in range(len(binary_text)):\n",
    "        if binary_text[line_idx][1] == '1':\n",
    "              ISA_example.append(binary_text[line_idx])\n",
    "        else:\n",
    "              Other_example.append(binary_text[line_idx])\n",
    "    print(f'List with ISA relations was created, Lenght: {len(ISA_example)}')\n",
    "    print(f'List with Other relations was created, Lenght: {len(Other_example)}')\n",
    "    return ISA_example, Other_example\n",
    "\n",
    "def convert_in_dataframe(file):\n",
    "    df = pd.DataFrame(columns = ['text', 'label'])\n",
    "    text = []\n",
    "    label = []\n",
    "    for idx in range(len(file)):\n",
    "        text.append(file[idx][0])\n",
    "        label.append(file[idx][1])\n",
    "\n",
    "    df['text'] = text\n",
    "    df['label'] = label\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of uploaded file:659\n",
      "List with ISA relations was created, Lenght: 94\n",
      "List with Other relations was created, Lenght: 565\n"
     ]
    }
   ],
   "source": [
    "train_ISA, train_Other = create_new_arrays(train_path_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide test_file into two lists: test_text includes only texts, test_labels includes only labels for each text from test_textt. It is nessesary for prediction and getting metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of uploaded file:74\n"
     ]
    }
   ],
   "source": [
    "test_file = binary_convert(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = []\n",
    "test_label = []\n",
    "\n",
    "for text_raw,label in test_file:\n",
    "    test_text.append(text_raw)\n",
    "    test_label.append(label)\n",
    "assert len(test_text) == len(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_df = pd.DataFrame(test_text)\n",
    "test_label_df = pd.DataFrame(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_df.to_csv('data/test_text.csv', index = False, header=False, sep = '\\t')\n",
    "test_label_df.to_csv('data/test_label.csv', index = False, header=False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide our train file on train and evaluation sets, where train set includes 65 texts with ISA relations and 200 texts with other relations, evaluation set includes 30 texts with ISA relations and 150 texts with other relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = []\n",
    "for idx in range(len(train_ISA)):\n",
    "    if idx < 65:\n",
    "        train_set.append(train_ISA[idx])\n",
    "\n",
    "for idx in range(len(train_Other)):\n",
    "    if idx < 200:\n",
    "        train_set.append(train_Other[idx])\n",
    "\n",
    "np.random.shuffle(train_set)\n",
    "\n",
    "eval_set = []\n",
    "for idx in range(len(train_ISA)):\n",
    "    if idx > 64:\n",
    "        eval_set.append(train_ISA[idx])\n",
    "\n",
    "for idx in range(len(train_Other)):\n",
    "    if idx > 199 and idx < 350:\n",
    "        eval_set.append(train_Other[idx])\n",
    "\n",
    "np.random.shuffle(eval_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save new txt files with binary classification in csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = convert_in_dataframe(train_set)\n",
    "train_df.to_csv('data/train_file.csv', index = False, header=False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = convert_in_dataframe(eval_set)\n",
    "eval_df.to_csv('data/eval_file.csv', index = False, header=False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = convert_in_dataframe(test_file)\n",
    "test_df.to_csv('data/test_file.csv', index = False, header=False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train set and eval with balanced classes\n",
    "\n",
    "Length of uploaded file: 659\n",
    "\n",
    "\n",
    "List with ISA relations was created, Lenght: 94\n",
    "\n",
    "\n",
    "List with Other relations was created, Lenght: 565\n",
    "\n",
    "\n",
    "Select the 70 ISA rlations and 70 Other relations for train\n",
    "And 24 ISA rlations and 100 Other relations for eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_balanced = []\n",
    "for idx in range(len(train_ISA)):\n",
    "    if idx < 70:\n",
    "        train_balanced.append(train_ISA[idx])\n",
    "\n",
    "for idx in range(len(train_Other)):\n",
    "    if idx < 70:\n",
    "        train_balanced.append(train_Other[idx])\n",
    "\n",
    "np.random.shuffle(train_balanced)\n",
    "\n",
    "eval_balanced = []\n",
    "for idx in range(len(train_ISA)):\n",
    "    if idx > 69:\n",
    "        eval_balanced.append(train_ISA[idx])\n",
    "\n",
    "for idx in range(len(train_Other)):\n",
    "    if idx > 69 and idx < 169:\n",
    "        eval_balanced.append(train_Other[idx])\n",
    "\n",
    "np.random.shuffle(eval_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_balanced_df = convert_in_dataframe(train_balanced)\n",
    "train_balanced_df.to_csv('data/train_balanced.csv', index = False, header=False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_balanced_df = convert_in_dataframe(eval_balanced)\n",
    "eval_balanced_df.to_csv('data/eval_balanced.csv', index = False, header=False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train set and eval with balanced classes\n",
    "Select the 70 ISA rlations and 350 Other relations for train And 24 ISA rlations and 200 Other relations for eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unbalanced = []\n",
    "for idx in range(len(train_ISA)):\n",
    "    if idx < 70:\n",
    "        train_unbalanced.append(train_ISA[idx])\n",
    "\n",
    "for idx in range(len(train_Other)):\n",
    "    if idx < 350:\n",
    "        train_unbalanced.append(train_Other[idx])\n",
    "\n",
    "np.random.shuffle(train_unbalanced)\n",
    "\n",
    "eval_unbalanced = []\n",
    "for idx in range(len(train_ISA)):\n",
    "    if idx > 69:\n",
    "        eval_unbalanced.append(train_ISA[idx])\n",
    "\n",
    "for idx in range(len(train_Other)):\n",
    "    if idx > 349 and idx < 550:\n",
    "        eval_unbalanced.append(train_Other[idx])\n",
    "\n",
    "np.random.shuffle(eval_unbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unbalanced_df = convert_in_dataframe(train_unbalanced)\n",
    "train_unbalanced_df.to_csv('data/train_unbalanced.csv', index = False, header=False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_unbalanced_df = convert_in_dataframe(eval_unbalanced)\n",
    "eval_unbalanced_df.to_csv('data/eval_unbalanced.csv', index = False, header=False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
