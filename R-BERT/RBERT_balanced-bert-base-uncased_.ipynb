{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import logging\n",
    "import random\n",
    "import copy\n",
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer,AdamW, BertConfig, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertModel, BertPreTrainedModel\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = '../data/label.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "ADDITIONAL_SPECIAL_TOKENS = [\"<e1>\", \"</e1>\", \"<e2>\", \"</e2>\"]\n",
    "\n",
    "\n",
    "def get_label(args):\n",
    "    return [label.strip() for label in open(label_path, \"r\", encoding=\"utf-8\")]\n",
    "\n",
    "\n",
    "def load_tokenizer(args):\n",
    "    tokenizer = BertTokenizer.from_pretrained(args.model_name_or_path)\n",
    "    tokenizer.add_special_tokens({\"additional_special_tokens\": ADDITIONAL_SPECIAL_TOKENS})\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def write_prediction(args, output_file, preds):\n",
    "    \"\"\"\n",
    "    For official evaluation script\n",
    "    :param output_file: prediction_file_path (e.g. eval/proposed_answers.txt)\n",
    "    :param preds: [0,1,0,2,18,...]\n",
    "    \"\"\"\n",
    "    relation_labels = get_label(args)\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for idx, pred in enumerate(preds):\n",
    "            f.write(\"{}\\t{}\\n\".format(8001 + idx, relation_labels[pred]))\n",
    "\n",
    "\n",
    "def init_logger():\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO)\n",
    "\n",
    "\n",
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if not args.no_cuda and torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "    return acc(preds, labels)\n",
    "\n",
    "\n",
    "def simple_accuracy(preds, labels):\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "\n",
    "def acc(preds, labels, average=\"macro\"):\n",
    "    acc = simple_accuracy(preds, labels)\n",
    "    return {\n",
    "        \"acc\": acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils import get_label\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"\n",
    "    A single training/test example for simple sequence classification.\n",
    "    Args:\n",
    "        guid: Unique id for the example.\n",
    "        text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "        label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, label):\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.label = label\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.to_json_string())\n",
    "\n",
    "    def to_dict(self):\n",
    "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
    "        output = copy.deepcopy(self.__dict__)\n",
    "        return output\n",
    "\n",
    "    def to_json_string(self):\n",
    "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
    "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
    "\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"\n",
    "    A single set of features of data.\n",
    "    Args:\n",
    "        input_ids: Indices of input sequence tokens in the vocabulary.\n",
    "        attention_mask: Mask to avoid performing attention on padding token indices.\n",
    "            Mask values selected in ``[0, 1]``:\n",
    "            Usually  ``1`` for tokens that are NOT MASKED, ``0`` for MASKED (padded) tokens.\n",
    "        token_type_ids: Segment token indices to indicate first and second portions of the inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, attention_mask, token_type_ids, label_id, e1_mask, e2_mask):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.token_type_ids = token_type_ids\n",
    "        self.label_id = label_id\n",
    "        self.e1_mask = e1_mask\n",
    "        self.e2_mask = e2_mask\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.to_json_string())\n",
    "\n",
    "    def to_dict(self):\n",
    "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
    "        output = copy.deepcopy(self.__dict__)\n",
    "        return output\n",
    "\n",
    "    def to_json_string(self):\n",
    "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
    "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
    "\n",
    "\n",
    "class SemEvalProcessor(object):\n",
    "    \"\"\"Processor for the Semeval data set \"\"\"\n",
    "\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.relation_labels = get_label(args)\n",
    "\n",
    "    @classmethod\n",
    "    def _read_tsv(cls, input_file, quotechar=None):\n",
    "        \"\"\"Reads a tab separated value file.\"\"\"\n",
    "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
    "            lines = []\n",
    "            for line in reader:\n",
    "                lines.append(line)\n",
    "            return lines\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = line[0]\n",
    "            label = self.relation_labels.index(line[1])\n",
    "            if i % 1000 == 0:\n",
    "                logger.info(line)\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, label=label))\n",
    "        return examples\n",
    "\n",
    "\n",
    "    def get_examples(self, mode):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mode: train, dev, test\n",
    "        \"\"\"\n",
    "        file_to_read = None\n",
    "        if mode == \"train_file\":\n",
    "            file_to_read = self.args.train_file\n",
    "        elif mode == \"eval_file\":\n",
    "            file_to_read = self.args.test_file\n",
    "        elif mode == \"test_file\":\n",
    "            file_to_read = self.args.test_file\n",
    "\n",
    "        logger.info(\"LOOKING AT {}\".format(os.path.join(self.args.data_dir, file_to_read)))\n",
    "        return self._create_examples(self._read_tsv(os.path.join(self.args.data_dir, file_to_read)), mode)\n",
    "\n",
    "\n",
    "processors = {\"semeval\": SemEvalProcessor}\n",
    "\n",
    "\n",
    "def read_examples_from_file(data_dir, mode):\n",
    "    file_path = os.path.join(data_dir, \"{}.txt\".format(mode))\n",
    "    guid_index = 1\n",
    "    examples = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            if len(line) == 2:\n",
    "                text_a = line[0]\n",
    "                label = line[1]\n",
    "            else:\n",
    "                text_a = line[0]\n",
    "                label = \"NONE\"\n",
    "            examples.append(InputExample(guid=guid_index, text_a=text_a, label=label))\n",
    "            guid_index += 1\n",
    "\n",
    "    return examples\n",
    "\n",
    "def convert_examples_to_features(\n",
    "    examples,\n",
    "    max_seq_len,\n",
    "    tokenizer,\n",
    "    cls_token=\"[CLS]\",\n",
    "    cls_token_segment_id=0,\n",
    "    sep_token=\"[SEP]\",\n",
    "    pad_token=0,\n",
    "    pad_token_segment_id=0,\n",
    "    sequence_a_segment_id=0,\n",
    "    add_sep_token=False,\n",
    "    mask_padding_with_zero=True,\n",
    "):\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        if ex_index % 5000 == 0:\n",
    "            logger.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
    "\n",
    "        tokens_a = tokenizer.tokenize(example.text_a)\n",
    "\n",
    "        e11_p = tokens_a.index(\"<e1>\")  # the start position of entity1\n",
    "        e12_p = tokens_a.index(\"</e1>\")  # the end position of entity1\n",
    "        e21_p = tokens_a.index(\"<e2>\")  # the start position of entity2\n",
    "        e22_p = tokens_a.index(\"</e2>\")  # the end position of entity2\n",
    "\n",
    "        # Replace the token\n",
    "        tokens_a[e11_p] = \"$\"\n",
    "        tokens_a[e12_p] = \"$\"\n",
    "        tokens_a[e21_p] = \"#\"\n",
    "        tokens_a[e22_p] = \"#\"\n",
    "\n",
    "        # Add 1 because of the [CLS] token\n",
    "        e11_p += 1\n",
    "        e12_p += 1\n",
    "        e21_p += 1\n",
    "        e22_p += 1\n",
    "\n",
    "        # Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.\n",
    "        if add_sep_token:\n",
    "            special_tokens_count = 2\n",
    "        else:\n",
    "            special_tokens_count = 1\n",
    "        if len(tokens_a) > max_seq_len - special_tokens_count:\n",
    "            tokens_a = tokens_a[: (max_seq_len - special_tokens_count)]\n",
    "\n",
    "        tokens = tokens_a\n",
    "        if add_sep_token:\n",
    "            tokens += [sep_token]\n",
    "\n",
    "        token_type_ids = [sequence_a_segment_id] * len(tokens)\n",
    "\n",
    "        tokens = [cls_token] + tokens\n",
    "        token_type_ids = [cls_token_segment_id] + token_type_ids\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.\n",
    "        attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding_length = max_seq_len - len(input_ids)\n",
    "        input_ids = input_ids + ([pad_token] * padding_length)\n",
    "        attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)\n",
    "\n",
    "        # e1 mask, e2 mask\n",
    "        e1_mask = [0] * len(attention_mask)\n",
    "        e2_mask = [0] * len(attention_mask)\n",
    "\n",
    "        for i in range(e11_p, e12_p + 1):\n",
    "            e1_mask[i] = 1\n",
    "        for i in range(e21_p, e22_p + 1):\n",
    "            e2_mask[i] = 1\n",
    "\n",
    "        assert len(input_ids) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_ids), max_seq_len)\n",
    "        assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(\n",
    "            len(attention_mask), max_seq_len\n",
    "        )\n",
    "        assert len(token_type_ids) == max_seq_len, \"Error with token type length {} vs {}\".format(\n",
    "            len(token_type_ids), max_seq_len\n",
    "        )\n",
    "\n",
    "        label_id = int(example.label)\n",
    "\n",
    "        if ex_index < 5:\n",
    "            logger.info(\"*** Example ***\")\n",
    "            logger.info(\"guid: %s\" % example.guid)\n",
    "            logger.info(\"tokens: %s\" % \" \".join([str(x) for x in tokens]))\n",
    "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "            logger.info(\"attention_mask: %s\" % \" \".join([str(x) for x in attention_mask]))\n",
    "            logger.info(\"token_type_ids: %s\" % \" \".join([str(x) for x in token_type_ids]))\n",
    "            logger.info(\"label: %s (id = %d)\" % (example.label, label_id))\n",
    "            logger.info(\"e1_mask: %s\" % \" \".join([str(x) for x in e1_mask]))\n",
    "            logger.info(\"e2_mask: %s\" % \" \".join([str(x) for x in e2_mask]))\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "                label_id=label_id,\n",
    "                e1_mask=e1_mask,\n",
    "                e2_mask=e2_mask,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def load_and_cache_examples(args, tokenizer, mode):\n",
    "    processor = processors[args.task](args)\n",
    "\n",
    "    # Load data features from cache or dataset file\n",
    "    cached_features_file = os.path.join(\n",
    "        args.data_dir,\n",
    "        \"cached_{}_{}_{}_{}\".format(\n",
    "            mode,\n",
    "            args.task,\n",
    "            list(filter(None, args.model_name_or_path.split(\"/\"))).pop(),\n",
    "            args.max_seq_len,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    if os.path.exists(cached_features_file):\n",
    "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
    "        features = torch.load(cached_features_file)\n",
    "    else:\n",
    "        logger.info(\"Creating features from dataset file at %s\", args.data_dir)\n",
    "        if mode == \"train_file\":\n",
    "            examples = processor.get_examples(\"train_file\")\n",
    "        elif mode == \"eval_file\":\n",
    "            examples = processor.get_examples(\"eval_file\")\n",
    "        elif mode == \"test_file\":\n",
    "            examples = processor.get_examples(\"test_file\")\n",
    "        else:\n",
    "            raise Exception(\"For mode, Only train, dev, test is available\")\n",
    "\n",
    "        features = convert_examples_to_features(\n",
    "            examples, args.max_seq_len, tokenizer\n",
    "        )\n",
    "        logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
    "        torch.save(features, cached_features_file)\n",
    "\n",
    "    # Convert to Tensors and build dataset\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
    "    all_token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long)\n",
    "    all_e1_mask = torch.tensor([f.e1_mask for f in features], dtype=torch.long)  # add e1 mask\n",
    "    all_e2_mask = torch.tensor([f.e2_mask for f in features], dtype=torch.long)  # add e2 mask\n",
    "\n",
    "    all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "\n",
    "    dataset = TensorDataset(\n",
    "        all_input_ids,\n",
    "        all_attention_mask,\n",
    "        all_token_type_ids,\n",
    "        all_label_ids,\n",
    "        all_e1_mask,\n",
    "        all_e2_mask,\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.0, use_activation=True):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self.use_activation = use_activation\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        if self.use_activation:\n",
    "            x = self.tanh(x)\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class RBERT(BertPreTrainedModel):\n",
    "    def __init__(self, config, args):\n",
    "        super(RBERT, self).__init__(config)\n",
    "        self.bert = BertModel(config=config)  # Load pretrained bert\n",
    "\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.cls_fc_layer = FCLayer(config.hidden_size, config.hidden_size, args.dropout_rate)\n",
    "        self.entity_fc_layer = FCLayer(config.hidden_size, config.hidden_size, args.dropout_rate)\n",
    "        self.label_classifier = FCLayer(\n",
    "            config.hidden_size * 3,\n",
    "            config.num_labels,\n",
    "            args.dropout_rate,\n",
    "            use_activation=False,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def entity_average(hidden_output, e_mask):\n",
    "        \"\"\"\n",
    "        Average the entity hidden state vectors (H_i ~ H_j)\n",
    "        :param hidden_output: [batch_size, j-i+1, dim]\n",
    "        :param e_mask: [batch_size, max_seq_len]\n",
    "                e.g. e_mask[0] == [0, 0, 0, 1, 1, 1, 0, 0, ... 0]\n",
    "        :return: [batch_size, dim]\n",
    "        \"\"\"\n",
    "        e_mask_unsqueeze = e_mask.unsqueeze(1)  # [b, 1, j-i+1]\n",
    "        length_tensor = (e_mask != 0).sum(dim=1).unsqueeze(1)  # [batch_size, 1]\n",
    "\n",
    "        # [b, 1, j-i+1] * [b, j-i+1, dim] = [b, 1, dim] -> [b, dim]\n",
    "        sum_vector = torch.bmm(e_mask_unsqueeze.float(), hidden_output).squeeze(1)\n",
    "        avg_vector = sum_vector.float() / length_tensor.float()  # broadcasting\n",
    "        return avg_vector\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, labels, e1_mask, e2_mask):\n",
    "        outputs = self.bert(\n",
    "            input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids\n",
    "        )  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        sequence_output = outputs[0]\n",
    "        pooled_output = outputs[1]  # [CLS]\n",
    "\n",
    "        # Average\n",
    "        e1_h = self.entity_average(sequence_output, e1_mask)\n",
    "        e2_h = self.entity_average(sequence_output, e2_mask)\n",
    "\n",
    "        # Dropout -> tanh -> fc_layer (Share FC layer for e1 and e2)\n",
    "        pooled_output = self.cls_fc_layer(pooled_output)\n",
    "        e1_h = self.entity_fc_layer(e1_h)\n",
    "        e2_h = self.entity_fc_layer(e2_h)\n",
    "\n",
    "        # Concat -> fc_layer\n",
    "        concat_h = torch.cat([pooled_output, e1_h, e2_h], dim=-1)\n",
    "        logits = self.label_classifier(concat_h)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "\n",
    "        # Softmax\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                loss_fct = nn.MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = nn.CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), logits, (hidden_states), (attentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device(pred_config):\n",
    "    return \"cuda\" if torch.cuda.is_available() and not pred_config.no_cuda else \"cpu\"\n",
    "\n",
    "def convert_input_file_to_tensor_dataset(\n",
    "    args,\n",
    "    cls_token_segment_id=0,\n",
    "    pad_token_segment_id=0,\n",
    "    sequence_a_segment_id=0,\n",
    "    mask_padding_with_zero=True):\n",
    "    tokenizer = load_tokenizer(args)\n",
    "\n",
    "    # Setting based on the current model type\n",
    "    cls_token = tokenizer.cls_token\n",
    "    sep_token = tokenizer.sep_token\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    all_input_ids = []\n",
    "    all_attention_mask = []\n",
    "    all_token_type_ids = []\n",
    "    all_e1_mask = []\n",
    "    all_e2_mask = []\n",
    "\n",
    "    with open(args.input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            tokens = tokenizer.tokenize(line)\n",
    "\n",
    "            e11_p = tokens.index(\"<e1>\")  # the start position of entity1\n",
    "            e12_p = tokens.index(\"</e1>\")  # the end position of entity1\n",
    "            e21_p = tokens.index(\"<e2>\")  # the start position of entity2\n",
    "            e22_p = tokens.index(\"</e2>\")  # the end position of entity2\n",
    "\n",
    "            # Replace the token\n",
    "            tokens[e11_p] = \"$\"\n",
    "            tokens[e12_p] = \"$\"\n",
    "            tokens[e21_p] = \"#\"\n",
    "            tokens[e22_p] = \"#\"\n",
    "\n",
    "            # Add 1 because of the [CLS] token\n",
    "            e11_p += 1\n",
    "            e12_p += 1\n",
    "            e21_p += 1\n",
    "            e22_p += 1\n",
    "\n",
    "            # Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.\n",
    "            if args.add_sep_token:\n",
    "                special_tokens_count = 2\n",
    "            else:\n",
    "                special_tokens_count = 1\n",
    "            if len(tokens) > args.max_seq_len - special_tokens_count:\n",
    "                tokens = tokens[: (args.max_seq_len - special_tokens_count)]\n",
    "\n",
    "            # Add [SEP] token\n",
    "            if args.add_sep_token:\n",
    "                tokens += [sep_token]\n",
    "            token_type_ids = [sequence_a_segment_id] * len(tokens)\n",
    "\n",
    "            # Add [CLS] token\n",
    "            tokens = [cls_token] + tokens\n",
    "            token_type_ids = [cls_token_segment_id] + token_type_ids\n",
    "\n",
    "            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "            # The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.\n",
    "            attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "            # Zero-pad up to the sequence length.\n",
    "            padding_length = args.max_seq_len - len(input_ids)\n",
    "            input_ids = input_ids + ([pad_token_id] * padding_length)\n",
    "            attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "            token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)\n",
    "\n",
    "            # e1 mask, e2 mask\n",
    "            e1_mask = [0] * len(attention_mask)\n",
    "            e2_mask = [0] * len(attention_mask)\n",
    "\n",
    "            for i in range(e11_p, e12_p + 1):\n",
    "                e1_mask[i] = 1\n",
    "            for i in range(e21_p, e22_p + 1):\n",
    "                e2_mask[i] = 1\n",
    "\n",
    "            all_input_ids.append(input_ids)\n",
    "            all_attention_mask.append(attention_mask)\n",
    "            all_token_type_ids.append(token_type_ids)\n",
    "            all_e1_mask.append(e1_mask)\n",
    "            all_e2_mask.append(e2_mask)\n",
    "\n",
    "    # Change to Tensor\n",
    "    all_input_ids = torch.tensor(all_input_ids, dtype=torch.long)\n",
    "    all_attention_mask = torch.tensor(all_attention_mask, dtype=torch.long)\n",
    "    all_token_type_ids = torch.tensor(all_token_type_ids, dtype=torch.long)\n",
    "    all_e1_mask = torch.tensor(all_e1_mask, dtype=torch.long)\n",
    "    all_e2_mask = torch.tensor(all_e2_mask, dtype=torch.long)\n",
    "\n",
    "    dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_e1_mask, all_e2_mask)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self, args, train_dataset=None, dev_dataset=None, test_dataset=None):\n",
    "        self.args = args\n",
    "        self.train_dataset = train_dataset\n",
    "        self.dev_dataset = dev_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "\n",
    "        self.label_lst = get_label(args)\n",
    "        self.num_labels = len(self.label_lst)\n",
    "\n",
    "        self.config = BertConfig.from_pretrained(\n",
    "            args.model_name_or_path,\n",
    "            num_labels=self.num_labels,\n",
    "            finetuning_task=args.task,\n",
    "            id2label={str(i): label for i, label in enumerate(self.label_lst)},\n",
    "            label2id={label: i for i, label in enumerate(self.label_lst)},\n",
    "        )\n",
    "        self.model = RBERT.from_pretrained(args.model_name_or_path, config=self.config, args=args)\n",
    "\n",
    "        # GPU or CPU\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        \n",
    "    def evaluate(self, mode):\n",
    "        # We use test dataset because semeval doesn't have dev dataset\n",
    "        if mode == \"test\":\n",
    "            dataset = self.test_dataset\n",
    "        elif mode == \"dev\":\n",
    "            dataset = self.dev_dataset\n",
    "        else:\n",
    "            raise Exception(\"Only dev and test dataset available\")\n",
    "\n",
    "        eval_sampler = SequentialSampler(dataset)\n",
    "        eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=self.args.eval_batch_size)\n",
    "        # Eval!\n",
    "\n",
    "        eval_loss = 0.0\n",
    "        nb_eval_steps = 0\n",
    "        preds = None\n",
    "        out_label_ids = None\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "            batch = tuple(t.to(self.device) for t in batch)\n",
    "            with torch.no_grad():\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"token_type_ids\": batch[2],\n",
    "                    \"labels\": batch[3],\n",
    "                    \"e1_mask\": batch[4],\n",
    "                    \"e2_mask\": batch[5],\n",
    "                }\n",
    "                outputs = self.model(**inputs)\n",
    "                tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "                eval_loss += tmp_eval_loss.mean().item()\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "            if preds is None:\n",
    "                preds = logits.detach().cpu().numpy()\n",
    "                out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
    "            else:\n",
    "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "                out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "        eval_loss = eval_loss / nb_eval_steps\n",
    "        #results = {\"loss\": eval_loss}\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        write_prediction(self.args, os.path.join(self.args.eval_dir, \"proposed_answers_bert1.txt\"), preds)\n",
    "\n",
    "        results = {\"loss\": eval_loss, 'accuracy' : accuracy_score(out_label_ids, preds), \n",
    "                   'f1_score': f1_score(out_label_ids, preds, average='weighted'),\n",
    "                  'roc_auc': roc_auc_score(out_label_ids, preds)}\n",
    "\n",
    "          #result = compute_metrics(preds, out_label_ids)\n",
    "          #results.update(result)\n",
    "\n",
    "        logger.info(\"***** Eval results *****\")\n",
    "        for key in sorted(results.keys()):\n",
    "            logger.info(\"  {} = {:.4f}\".format(key, results[key]))\n",
    "\n",
    "        return results\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        train_sampler = RandomSampler(self.train_dataset)\n",
    "        train_dataloader = DataLoader(\n",
    "            self.train_dataset,\n",
    "            sampler=train_sampler,\n",
    "            batch_size=self.args.train_batch_size,\n",
    "        )\n",
    "\n",
    "        if self.args.max_steps > 0:\n",
    "            t_total = self.args.max_steps\n",
    "            self.args.num_train_epochs = (\n",
    "                self.args.max_steps // (len(train_dataloader) // self.args.gradient_accumulation_steps) + 1\n",
    "            )\n",
    "        else:\n",
    "            t_total = len(train_dataloader) // self.args.gradient_accumulation_steps * self.args.num_train_epochs\n",
    "\n",
    "        # Prepare optimizer and schedule (linear warmup and decay)\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": self.args.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=self.args.learning_rate,\n",
    "            eps=self.args.adam_epsilon,\n",
    "        )\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.args.warmup_steps,\n",
    "            num_training_steps=t_total,\n",
    "        )\n",
    "        # Train!\n",
    "\n",
    "        global_step = 0\n",
    "        tr_loss = 0.0\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        train_iterator = trange(int(self.args.num_train_epochs), desc=\"Epoch\")\n",
    "\n",
    "        for _ in train_iterator:\n",
    "            epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "            for step, batch in enumerate(epoch_iterator):\n",
    "                self.model.train()\n",
    "                batch = tuple(t.to(self.device) for t in batch)  # GPU or CPU\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"token_type_ids\": batch[2],\n",
    "                    \"labels\": batch[3],\n",
    "                    \"e1_mask\": batch[4],\n",
    "                    \"e2_mask\": batch[5],\n",
    "                }\n",
    "                outputs = self.model(**inputs)\n",
    "                loss = outputs[0]\n",
    "\n",
    "                if self.args.gradient_accumulation_steps > 1:\n",
    "                    loss = loss / self.args.gradient_accumulation_steps\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                tr_loss += loss.item()\n",
    "                if (step + 1) % self.args.gradient_accumulation_steps == 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.args.max_grad_norm)\n",
    "\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()  # Update learning rate schedule\n",
    "                    self.model.zero_grad()\n",
    "                    global_step += 1\n",
    "\n",
    "            print(\"\\n====Evaluation====\")\n",
    "            print(\"\\nEvaluation: \", self.evaluate(\"test\"))\n",
    "            \n",
    "        self.save_model(self.model)\n",
    "\n",
    "    def save_model(self, model):\n",
    "        torch.save(model.state_dict(), 'model/model_bert_base1.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBERT_re(args):\n",
    "    set_seed(args)\n",
    "    tokenizer = load_tokenizer(args)\n",
    "\n",
    "    train_dataset = load_and_cache_examples(args, tokenizer, mode=\"train_file\")\n",
    "    test_dataset = load_and_cache_examples(args, tokenizer, mode=\"eval_file\")\n",
    "\n",
    "    trainer = Trainer(args, train_dataset=train_dataset, test_dataset=test_dataset)\n",
    "\n",
    "\n",
    "    if args.do_train:\n",
    "        trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer_args(object):\n",
    "    def __init__(self,\n",
    "                model_name_or_path = 'bert-base-uncased',\n",
    "                seed = 24,\n",
    "                task = \"semeval\",\n",
    "                train_file = 'train_balanced.csv', \n",
    "                test_file = 'eval_balanced.csv',\n",
    "                label_file = 'label.txt',  \n",
    "                dropout_rate = 0.1,\n",
    "                num_labels = 2,\n",
    "                learning_rate = 2e-5,\n",
    "                num_train_epochs = 11,\n",
    "                max_seq_len = 384,\n",
    "                train_batch_size = 16,\n",
    "                eval_batch_size = 16,\n",
    "                adam_epsilon = 1e-8,\n",
    "                gradient_accumulation_steps = 1,\n",
    "                max_grad_norm = 1.0,\n",
    "                logging_steps = 250,\n",
    "                save_steps = 250,\n",
    "                weight_decay = 0.0,\n",
    "                add_sep_token = True,\n",
    "                do_train = True,\n",
    "                no_cuda = True,\n",
    "                do_eval = True,\n",
    "                max_steps = -1,\n",
    "                warmup_steps = 0,\n",
    "                model_dir = 'model/',\n",
    "                data_dir = '../data/',\n",
    "                eval_dir = '../data/'\n",
    "                ):\n",
    "\n",
    "        super(Trainer_args, self).__init__()\n",
    "\n",
    "        self.train_file = train_file\n",
    "        self.test_file = test_file\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.num_labels = num_labels\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_train_epochs = num_train_epochs\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.adam_epsilon = adam_epsilon\n",
    "        self.gradient_accumulation_steps = gradient_accumulation_steps\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        self.logging_steps = logging_steps\n",
    "        self.save_steps = save_steps\n",
    "        self.weight_decay = weight_decay\n",
    "        self.data_dir = data_dir\n",
    "        self.model_name_or_path = model_name_or_path\n",
    "        self.seed = seed\n",
    "        self.task = task\n",
    "        self.add_sep_token = add_sep_token\n",
    "        self.do_train = do_train\n",
    "        self.no_cuda = no_cuda\n",
    "        self.max_steps = max_steps\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.model_dir = model_dir\n",
    "        self.label_file = label_file\n",
    "        self.eval_batch_size = eval_batch_size\n",
    "        self.do_eval = do_eval\n",
    "        self.eval_dir = eval_dir\n",
    "        return \n",
    "args = Trainer_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../data/train_balanced.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing RBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing RBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls_fc_layer.linear.weight', 'cls_fc_layer.linear.bias', 'entity_fc_layer.linear.weight', 'entity_fc_layer.linear.bias', 'label_classifier.linear.weight', 'label_classifier.linear.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   0%|                                            | 0/11 [00:00<?, ?it/s]\n",
      "Iteration:   0%|                                        | 0/17 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   6%|█▊                             | 1/17 [01:53<30:19, 113.75s/it]\u001b[A\n",
      "Iteration:  12%|███▋                           | 2/17 [04:10<30:07, 120.51s/it]\u001b[A\n",
      "Iteration:  18%|█████▍                         | 3/17 [06:19<28:45, 123.24s/it]\u001b[A\n",
      "Iteration:  24%|███████▎                       | 4/17 [08:23<26:41, 123.19s/it]\u001b[A\n",
      "Iteration:  29%|█████████                      | 5/17 [10:41<25:32, 127.71s/it]\u001b[A\n",
      "Iteration:  35%|██████████▉                    | 6/17 [13:10<24:36, 134.24s/it]\u001b[A\n",
      "Iteration:  41%|████████████▊                  | 7/17 [15:42<23:14, 139.41s/it]\u001b[A\n",
      "Iteration:  47%|██████████████▌                | 8/17 [18:00<20:53, 139.26s/it]\u001b[A\n",
      "Iteration:  53%|████████████████▍              | 9/17 [20:23<18:40, 140.03s/it]\u001b[A\n",
      "Iteration:  59%|█████████████████▋            | 10/17 [22:55<16:46, 143.79s/it]\u001b[A\n",
      "Iteration:  65%|███████████████████▍          | 11/17 [25:24<14:32, 145.39s/it]\u001b[A\n",
      "Iteration:  71%|█████████████████████▏        | 12/17 [28:04<12:28, 149.73s/it]\u001b[A\n",
      "Iteration:  76%|██████████████████████▉       | 13/17 [30:36<10:01, 150.33s/it]\u001b[A\n",
      "Iteration:  82%|████████████████████████▋     | 14/17 [32:39<07:06, 142.17s/it]\u001b[A\n",
      "Iteration:  88%|██████████████████████████▍   | 15/17 [34:53<04:39, 139.77s/it]\u001b[A\n",
      "Iteration:  94%|████████████████████████████▏ | 16/17 [36:58<02:15, 135.36s/it]\u001b[A\n",
      "Iteration: 100%|██████████████████████████████| 17/17 [38:01<00:00, 134.19s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                       | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   8%|██▌                            | 1/12 [00:37<06:48, 37.15s/it]\u001b[A\n",
      "Evaluating:  17%|█████▏                         | 2/12 [01:15<06:16, 37.62s/it]\u001b[A\n",
      "Evaluating:  25%|███████▊                       | 3/12 [01:54<05:42, 38.02s/it]\u001b[A\n",
      "Evaluating:  33%|██████████▎                    | 4/12 [02:33<05:05, 38.18s/it]\u001b[A\n",
      "Evaluating:  42%|████████████▉                  | 5/12 [03:12<04:28, 38.36s/it]\u001b[A\n",
      "Evaluating:  50%|███████████████▌               | 6/12 [03:51<03:51, 38.54s/it]\u001b[A\n",
      "Evaluating:  58%|██████████████████             | 7/12 [04:31<03:15, 39.17s/it]\u001b[A\n",
      "Evaluating:  67%|████████████████████▋          | 8/12 [05:14<02:41, 40.28s/it]\u001b[A\n",
      "Evaluating:  75%|███████████████████████▎       | 9/12 [05:56<02:02, 40.89s/it]\u001b[A\n",
      "Evaluating:  83%|█████████████████████████     | 10/12 [06:40<01:23, 41.55s/it]\u001b[A\n",
      "Evaluating:  92%|███████████████████████████▌  | 11/12 [07:22<00:41, 41.72s/it]\u001b[A\n",
      "Evaluating: 100%|██████████████████████████████| 12/12 [07:31<00:00, 37.61s/it]\u001b[A\n",
      "Epoch:   9%|██▉                             | 1/11 [45:34<7:35:47, 2734.74s/it]\n",
      "Iteration:   0%|                                        | 0/17 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.5066063528259596, 'accuracy': 0.8379888268156425, 'f1_score': 0.7641235502878199, 'roc_auc': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|█▊                             | 1/17 [02:34<41:05, 154.06s/it]\u001b[A\n",
      "Iteration:  12%|███▋                           | 2/17 [05:52<41:45, 167.04s/it]\u001b[A\n",
      "Iteration:  18%|█████▍                         | 3/17 [07:40<34:54, 149.57s/it]\u001b[A\n",
      "Iteration:  24%|███████▎                       | 4/17 [09:37<30:14, 139.60s/it]\u001b[A\n",
      "Iteration:  29%|█████████                      | 5/17 [11:27<26:13, 131.13s/it]\u001b[A\n",
      "Iteration:  35%|██████████▉                    | 6/17 [13:27<23:21, 127.44s/it]\u001b[A\n",
      "Iteration:  41%|████████████▊                  | 7/17 [15:22<20:37, 123.79s/it]\u001b[A\n",
      "Iteration:  47%|██████████████▌                | 8/17 [17:19<18:08, 120.92s/it]\u001b[A\n",
      "Iteration:  53%|████████████████▍              | 9/17 [19:22<16:18, 122.36s/it]\u001b[A\n",
      "Iteration:  59%|█████████████████▋            | 10/17 [21:22<14:11, 121.70s/it]\u001b[A\n",
      "Iteration:  65%|███████████████████▍          | 11/17 [23:52<12:52, 128.78s/it]\u001b[A\n",
      "Iteration:  71%|█████████████████████▏        | 12/17 [28:00<13:49, 165.84s/it]\u001b[A\n",
      "Iteration:  76%|██████████████████████▉       | 13/17 [34:59<16:07, 241.87s/it]\u001b[A\n",
      "Iteration:  82%|████████████████████████▋     | 14/17 [36:54<10:11, 204.00s/it]\u001b[A\n",
      "Iteration:  88%|██████████████████████████▍   | 15/17 [38:40<05:49, 174.54s/it]\u001b[A\n",
      "Iteration:  94%|████████████████████████████▏ | 16/17 [40:25<02:33, 153.78s/it]\u001b[A\n",
      "Iteration: 100%|██████████████████████████████| 17/17 [41:28<00:00, 146.36s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                       | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   8%|██▌                            | 1/12 [00:37<06:57, 37.93s/it]\u001b[A\n",
      "Evaluating:  17%|█████▏                         | 2/12 [01:16<06:19, 38.00s/it]\u001b[A\n",
      "Evaluating:  25%|███████▊                       | 3/12 [01:54<05:43, 38.14s/it]\u001b[A\n",
      "Evaluating:  33%|██████████▎                    | 4/12 [02:32<05:05, 38.17s/it]\u001b[A\n",
      "Evaluating:  42%|████████████▉                  | 5/12 [03:11<04:28, 38.30s/it]\u001b[A\n",
      "Evaluating:  50%|███████████████▌               | 6/12 [03:49<03:50, 38.34s/it]\u001b[A\n",
      "Evaluating:  58%|██████████████████             | 7/12 [04:28<03:11, 38.38s/it]\u001b[A\n",
      "Evaluating:  67%|████████████████████▋          | 8/12 [05:06<02:33, 38.36s/it]\u001b[A\n",
      "Evaluating:  75%|███████████████████████▎       | 9/12 [05:44<01:54, 38.13s/it]\u001b[A\n",
      "Evaluating:  83%|█████████████████████████     | 10/12 [06:20<01:15, 37.53s/it]\u001b[A\n",
      "Evaluating:  92%|███████████████████████████▌  | 11/12 [06:56<00:37, 37.11s/it]\u001b[A\n",
      "Evaluating: 100%|██████████████████████████████| 12/12 [07:04<00:00, 35.40s/it]\u001b[A\n",
      "Epoch:  18%|█████▍                        | 2/11 [1:34:13<6:58:28, 2789.82s/it]\n",
      "Iteration:   0%|                                        | 0/17 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.5187283555666605, 'accuracy': 0.8324022346368715, 'f1_score': 0.7869171958314539, 'roc_auc': 0.5383908045977012}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|█▊                             | 1/17 [01:45<28:05, 105.34s/it]\u001b[A\n",
      "Iteration:  12%|███▋                           | 2/17 [03:32<26:23, 105.59s/it]\u001b[A\n",
      "Iteration:  18%|█████▍                         | 3/17 [05:14<24:26, 104.74s/it]\u001b[A\n",
      "Iteration:  24%|███████▎                       | 4/17 [06:57<22:36, 104.37s/it]\u001b[A\n",
      "Iteration:  29%|█████████                      | 5/17 [08:43<20:56, 104.69s/it]\u001b[A\n",
      "Iteration:  35%|██████████▉                    | 6/17 [10:26<19:07, 104.35s/it]\u001b[A\n",
      "Iteration:  41%|████████████▊                  | 7/17 [12:10<17:21, 104.19s/it]\u001b[A\n",
      "Iteration:  47%|██████████████▌                | 8/17 [13:58<15:47, 105.33s/it]\u001b[A\n",
      "Iteration:  53%|████████████████▍              | 9/17 [15:41<13:56, 104.60s/it]\u001b[A\n",
      "Iteration:  59%|█████████████████▋            | 10/17 [17:26<12:12, 104.69s/it]\u001b[A\n",
      "Iteration:  65%|███████████████████▍          | 11/17 [19:07<10:22, 103.69s/it]\u001b[A\n",
      "Iteration:  71%|█████████████████████▏        | 12/17 [20:54<08:43, 104.69s/it]\u001b[A\n",
      "Iteration:  76%|██████████████████████▉       | 13/17 [22:37<06:56, 104.23s/it]\u001b[A\n",
      "Iteration:  82%|████████████████████████▋     | 14/17 [24:25<05:15, 105.28s/it]\u001b[A\n",
      "Iteration:  88%|██████████████████████████▍   | 15/17 [26:11<03:31, 105.57s/it]\u001b[A\n",
      "Iteration:  94%|████████████████████████████▏ | 16/17 [27:57<01:45, 105.70s/it]\u001b[A\n",
      "Iteration: 100%|██████████████████████████████| 17/17 [28:57<00:00, 102.18s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                       | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   8%|██▌                            | 1/12 [00:36<06:40, 36.44s/it]\u001b[A\n",
      "Evaluating:  17%|█████▏                         | 2/12 [01:13<06:05, 36.53s/it]\u001b[A\n",
      "Evaluating:  25%|███████▊                       | 3/12 [01:49<05:29, 36.58s/it]\u001b[A\n",
      "Evaluating:  33%|██████████▎                    | 4/12 [02:26<04:52, 36.50s/it]\u001b[A\n",
      "Evaluating:  42%|████████████▉                  | 5/12 [03:02<04:15, 36.55s/it]\u001b[A\n",
      "Evaluating:  50%|███████████████▌               | 6/12 [03:39<03:39, 36.57s/it]\u001b[A\n",
      "Evaluating:  58%|██████████████████             | 7/12 [04:16<03:02, 36.57s/it]\u001b[A\n",
      "Evaluating:  67%|████████████████████▋          | 8/12 [04:52<02:26, 36.56s/it]\u001b[A\n",
      "Evaluating:  75%|███████████████████████▎       | 9/12 [05:29<01:49, 36.61s/it]\u001b[A\n",
      "Evaluating:  83%|█████████████████████████     | 10/12 [06:05<01:12, 36.49s/it]\u001b[A\n",
      "Evaluating:  92%|███████████████████████████▌  | 11/12 [06:41<00:36, 36.40s/it]\u001b[A\n",
      "Evaluating: 100%|██████████████████████████████| 12/12 [06:48<00:00, 34.08s/it]\u001b[A\n",
      "Epoch:  27%|████████▏                     | 3/11 [2:10:04<5:46:26, 2598.33s/it]\n",
      "Iteration:   0%|                                        | 0/17 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.4698467080791791, 'accuracy': 0.8379888268156425, 'f1_score': 0.8033493508353843, 'roc_auc': 0.5695402298850575}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|█▊                             | 1/17 [01:44<27:56, 104.77s/it]\u001b[A\n",
      "Iteration:  12%|███▋                           | 2/17 [03:32<26:26, 105.77s/it]\u001b[A\n",
      "Iteration:  18%|█████▍                         | 3/17 [05:19<24:42, 105.90s/it]\u001b[A\n",
      "Iteration:  24%|███████▎                       | 4/17 [07:03<22:49, 105.32s/it]\u001b[A\n",
      "Iteration:  29%|█████████                      | 5/17 [08:48<21:05, 105.42s/it]\u001b[A\n",
      "Iteration:  35%|██████████▉                    | 6/17 [10:34<19:20, 105.53s/it]\u001b[A\n",
      "Iteration:  41%|████████████▊                  | 7/17 [12:18<17:31, 105.14s/it]\u001b[A\n",
      "Iteration:  47%|██████████████▌                | 8/17 [14:03<15:44, 104.94s/it]\u001b[A\n",
      "Iteration:  53%|████████████████▍              | 9/17 [15:49<14:03, 105.43s/it]\u001b[A\n",
      "Iteration:  59%|█████████████████▋            | 10/17 [17:37<12:23, 106.25s/it]\u001b[A\n",
      "Iteration:  65%|███████████████████▍          | 11/17 [19:21<10:32, 105.39s/it]\u001b[A\n",
      "Iteration:  71%|█████████████████████▏        | 12/17 [21:04<08:43, 104.75s/it]\u001b[A\n",
      "Iteration:  76%|██████████████████████▉       | 13/17 [22:48<06:57, 104.39s/it]\u001b[A\n",
      "Iteration:  82%|████████████████████████▋     | 14/17 [24:32<05:12, 104.27s/it]\u001b[A\n",
      "Iteration:  88%|██████████████████████████▍   | 15/17 [26:15<03:27, 103.98s/it]\u001b[A\n",
      "Iteration:  94%|████████████████████████████▏ | 16/17 [27:59<01:43, 103.92s/it]\u001b[A\n",
      "Iteration: 100%|██████████████████████████████| 17/17 [28:57<00:00, 102.21s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                       | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   8%|██▌                            | 1/12 [00:37<06:55, 37.74s/it]\u001b[A\n",
      "Evaluating:  17%|█████▏                         | 2/12 [01:14<06:14, 37.45s/it]\u001b[A\n",
      "Evaluating:  25%|███████▊                       | 3/12 [01:51<05:35, 37.24s/it]\u001b[A\n",
      "Evaluating:  33%|██████████▎                    | 4/12 [02:27<04:55, 37.00s/it]\u001b[A\n",
      "Evaluating:  42%|████████████▉                  | 5/12 [03:04<04:18, 36.92s/it]\u001b[A\n",
      "Evaluating:  50%|███████████████▌               | 6/12 [03:41<03:41, 36.86s/it]\u001b[A\n",
      "Evaluating:  58%|██████████████████             | 7/12 [04:17<03:03, 36.72s/it]\u001b[A\n",
      "Evaluating:  67%|████████████████████▋          | 8/12 [04:54<02:26, 36.64s/it]\u001b[A\n",
      "Evaluating:  75%|███████████████████████▎       | 9/12 [05:30<01:49, 36.59s/it]\u001b[A\n",
      "Evaluating:  83%|█████████████████████████     | 10/12 [06:06<01:12, 36.49s/it]\u001b[A\n",
      "Evaluating:  92%|███████████████████████████▌  | 11/12 [06:43<00:36, 36.45s/it]\u001b[A\n",
      "Evaluating: 100%|██████████████████████████████| 12/12 [06:50<00:00, 34.19s/it]\u001b[A\n",
      "Epoch:  36%|██████████▉                   | 4/11 [2:45:55<4:47:29, 2464.17s/it]\n",
      "Iteration:   0%|                                        | 0/17 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.44764966517686844, 'accuracy': 0.8324022346368715, 'f1_score': 0.8047218321597785, 'roc_auc': 0.5801149425287356}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|█▊                             | 1/17 [01:41<27:08, 101.78s/it]\u001b[A\n",
      "Iteration:  12%|███▋                           | 2/17 [03:27<25:46, 103.09s/it]\u001b[A\n",
      "Iteration:  18%|█████▍                         | 3/17 [05:13<24:12, 103.75s/it]\u001b[A\n",
      "Iteration:  24%|███████▎                       | 4/17 [07:01<22:44, 104.98s/it]\u001b[A\n",
      "Iteration:  29%|█████████                      | 5/17 [08:48<21:09, 105.76s/it]\u001b[A\n",
      "Iteration:  35%|██████████▉                    | 6/17 [10:38<19:35, 106.89s/it]\u001b[A\n",
      "Iteration:  41%|████████████▊                  | 7/17 [12:27<17:57, 107.74s/it]\u001b[A\n",
      "Iteration:  47%|██████████████▌                | 8/17 [14:14<16:06, 107.36s/it]\u001b[A\n",
      "Iteration:  53%|████████████████▍              | 9/17 [15:58<14:11, 106.50s/it]\u001b[A\n",
      "Iteration:  59%|█████████████████▋            | 10/17 [17:44<12:23, 106.27s/it]\u001b[A\n",
      "Iteration:  65%|███████████████████▍          | 11/17 [19:29<10:35, 105.98s/it]\u001b[A\n",
      "Iteration:  71%|█████████████████████▏        | 12/17 [21:15<08:48, 105.75s/it]\u001b[A\n",
      "Iteration:  76%|██████████████████████▉       | 13/17 [22:59<07:01, 105.34s/it]\u001b[A\n",
      "Iteration:  82%|████████████████████████▋     | 14/17 [24:47<05:18, 106.10s/it]\u001b[A\n",
      "Iteration:  88%|██████████████████████████▍   | 15/17 [26:31<03:30, 105.49s/it]\u001b[A\n",
      "Iteration:  94%|████████████████████████████▏ | 16/17 [28:17<01:45, 105.56s/it]\u001b[A\n",
      "Iteration: 100%|██████████████████████████████| 17/17 [29:15<00:00, 103.27s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                       | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   8%|██▌                            | 1/12 [00:36<06:45, 36.91s/it]\u001b[A\n",
      "Evaluating:  17%|█████▏                         | 2/12 [01:14<06:09, 36.97s/it]\u001b[A\n",
      "Evaluating:  25%|███████▊                       | 3/12 [01:50<05:32, 36.94s/it]\u001b[A\n",
      "Evaluating:  33%|██████████▎                    | 4/12 [02:27<04:54, 36.80s/it]\u001b[A\n",
      "Evaluating:  42%|████████████▉                  | 5/12 [03:04<04:17, 36.79s/it]\u001b[A\n",
      "Evaluating:  50%|███████████████▌               | 6/12 [03:41<03:41, 36.87s/it]\u001b[A\n",
      "Evaluating:  58%|██████████████████             | 7/12 [04:17<03:04, 36.84s/it]\u001b[A\n",
      "Evaluating:  67%|████████████████████▋          | 8/12 [04:54<02:27, 36.78s/it]\u001b[A\n",
      "Evaluating:  75%|███████████████████████▎       | 9/12 [05:31<01:50, 36.71s/it]\u001b[A\n",
      "Evaluating:  83%|█████████████████████████     | 10/12 [06:07<01:13, 36.70s/it]\u001b[A\n",
      "Evaluating:  92%|███████████████████████████▌  | 11/12 [06:44<00:36, 36.65s/it]\u001b[A\n",
      "Evaluating: 100%|██████████████████████████████| 12/12 [06:51<00:00, 34.30s/it]\u001b[A\n",
      "Epoch:  45%|█████████████▋                | 5/11 [3:22:08<3:57:41, 2376.86s/it]\n",
      "Iteration:   0%|                                        | 0/17 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.44092554599046707, 'accuracy': 0.8491620111731844, 'f1_score': 0.8305067199742983, 'roc_auc': 0.6318390804597701}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|█▊                             | 1/17 [01:46<28:27, 106.70s/it]\u001b[A\n",
      "Iteration:  12%|███▋                           | 2/17 [03:35<26:49, 107.33s/it]\u001b[A\n",
      "Iteration:  18%|█████▍                         | 3/17 [05:25<25:12, 108.01s/it]\u001b[A\n",
      "Iteration:  24%|███████▎                       | 4/17 [07:14<23:27, 108.30s/it]\u001b[A\n",
      "Iteration:  29%|█████████                      | 5/17 [09:03<21:44, 108.72s/it]\u001b[A\n",
      "Iteration:  35%|██████████▉                    | 6/17 [10:50<19:47, 107.98s/it]\u001b[A\n",
      "Iteration:  41%|████████████▊                  | 7/17 [12:38<18:00, 108.05s/it]\u001b[A\n",
      "Iteration:  47%|██████████████▌                | 8/17 [14:27<16:15, 108.39s/it]\u001b[A\n",
      "Iteration:  53%|████████████████▍              | 9/17 [16:14<14:23, 107.92s/it]\u001b[A\n",
      "Iteration:  59%|█████████████████▋            | 10/17 [18:03<12:37, 108.23s/it]\u001b[A\n",
      "Iteration:  65%|███████████████████▍          | 11/17 [19:52<10:50, 108.44s/it]\u001b[A\n",
      "Iteration:  71%|█████████████████████▏        | 12/17 [21:41<09:03, 108.72s/it]\u001b[A\n",
      "Iteration:  76%|██████████████████████▉       | 13/17 [23:30<07:15, 108.88s/it]\u001b[A\n",
      "Iteration:  82%|████████████████████████▋     | 14/17 [25:19<05:26, 108.82s/it]\u001b[A\n",
      "Iteration:  88%|██████████████████████████▍   | 15/17 [27:08<03:37, 108.88s/it]\u001b[A\n",
      "Iteration:  94%|████████████████████████████▏ | 16/17 [28:57<01:48, 108.92s/it]\u001b[A\n",
      "Iteration: 100%|██████████████████████████████| 17/17 [30:02<00:00, 106.01s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                       | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   8%|██▌                            | 1/12 [00:38<07:01, 38.31s/it]\u001b[A\n",
      "Evaluating:  17%|█████▏                         | 2/12 [01:16<06:23, 38.38s/it]\u001b[A\n",
      "Evaluating:  25%|███████▊                       | 3/12 [01:54<05:44, 38.25s/it]\u001b[A\n",
      "Evaluating:  33%|██████████▎                    | 4/12 [02:32<05:04, 38.09s/it]\u001b[A\n",
      "Evaluating:  42%|████████████▉                  | 5/12 [03:09<04:25, 37.87s/it]\u001b[A\n",
      "Evaluating:  50%|███████████████▌               | 6/12 [03:48<03:48, 38.13s/it]\u001b[A\n",
      "Evaluating:  58%|██████████████████             | 7/12 [04:27<03:11, 38.22s/it]\u001b[A\n",
      "Evaluating:  67%|████████████████████▋          | 8/12 [05:05<02:33, 38.38s/it]\u001b[A\n",
      "Evaluating:  75%|███████████████████████▎       | 9/12 [05:44<01:55, 38.37s/it]\u001b[A\n",
      "Evaluating:  83%|█████████████████████████     | 10/12 [06:24<01:17, 38.92s/it]\u001b[A\n",
      "Evaluating:  92%|███████████████████████████▌  | 11/12 [07:02<00:38, 38.60s/it]\u001b[A\n",
      "Evaluating: 100%|██████████████████████████████| 12/12 [07:10<00:00, 35.86s/it]\u001b[A\n",
      "Epoch:  55%|████████████████▎             | 6/11 [3:59:23<3:14:31, 2334.22s/it]\n",
      "Iteration:   0%|                                        | 0/17 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.45442944516738254, 'accuracy': 0.8491620111731844, 'f1_score': 0.8341783100186015, 'roc_auc': 0.6457471264367816}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|█▊                             | 1/17 [01:47<28:32, 107.02s/it]\u001b[A\n",
      "Iteration:  12%|███▋                           | 2/17 [03:31<26:33, 106.26s/it]\u001b[A\n",
      "Iteration:  18%|█████▍                         | 3/17 [05:18<24:51, 106.53s/it]\u001b[A\n",
      "Iteration:  24%|███████▎                       | 4/17 [07:02<22:54, 105.72s/it]\u001b[A\n",
      "Iteration:  29%|█████████                      | 5/17 [08:46<21:01, 105.10s/it]\u001b[A\n",
      "Iteration:  35%|██████████▉                    | 6/17 [10:30<19:14, 104.98s/it]\u001b[A\n",
      "Iteration:  41%|████████████▊                  | 7/17 [12:20<17:44, 106.49s/it]\u001b[A\n",
      "Iteration:  47%|██████████████▌                | 8/17 [14:06<15:55, 106.17s/it]\u001b[A\n",
      "Iteration:  53%|████████████████▍              | 9/17 [15:51<14:07, 105.94s/it]\u001b[A\n",
      "Iteration:  59%|█████████████████▋            | 10/17 [17:39<12:26, 106.58s/it]\u001b[A\n",
      "Iteration:  65%|███████████████████▍          | 11/17 [19:28<10:43, 107.18s/it]\u001b[A\n",
      "Iteration:  71%|█████████████████████▏        | 12/17 [21:16<08:57, 107.51s/it]\u001b[A\n",
      "Iteration:  76%|██████████████████████▉       | 13/17 [23:04<07:10, 107.53s/it]\u001b[A\n",
      "Iteration:  82%|████████████████████████▋     | 14/17 [24:47<05:18, 106.26s/it]\u001b[A\n",
      "Iteration:  88%|██████████████████████████▍   | 15/17 [26:33<03:32, 106.19s/it]\u001b[A\n",
      "Iteration:  94%|████████████████████████████▏ | 16/17 [28:20<01:46, 106.31s/it]\u001b[A\n",
      "Iteration: 100%|██████████████████████████████| 17/17 [29:18<00:00, 103.44s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                       | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   8%|██▌                            | 1/12 [00:36<06:39, 36.31s/it]\u001b[A\n",
      "Evaluating:  17%|█████▏                         | 2/12 [01:13<06:04, 36.44s/it]\u001b[A\n",
      "Evaluating:  25%|███████▊                       | 3/12 [01:50<05:30, 36.69s/it]\u001b[A\n",
      "Evaluating:  33%|██████████▎                    | 4/12 [02:27<04:53, 36.69s/it]\u001b[A\n",
      "Evaluating:  42%|████████████▉                  | 5/12 [03:04<04:17, 36.82s/it]\u001b[A\n",
      "Evaluating:  50%|███████████████▌               | 6/12 [03:41<03:41, 36.88s/it]\u001b[A\n",
      "Evaluating:  58%|██████████████████             | 7/12 [04:17<03:03, 36.78s/it]\u001b[A\n",
      "Evaluating:  67%|████████████████████▋          | 8/12 [04:54<02:27, 36.76s/it]\u001b[A\n",
      "Evaluating:  75%|███████████████████████▎       | 9/12 [05:30<01:49, 36.65s/it]\u001b[A\n",
      "Evaluating:  83%|█████████████████████████     | 10/12 [06:07<01:13, 36.57s/it]\u001b[A\n",
      "Evaluating:  92%|███████████████████████████▌  | 11/12 [06:44<00:36, 36.73s/it]\u001b[A\n",
      "Evaluating: 100%|██████████████████████████████| 12/12 [06:52<00:00, 34.41s/it]\u001b[A\n",
      "Epoch:  64%|███████████████████           | 7/11 [4:35:37<2:32:24, 2286.14s/it]\n",
      "Iteration:   0%|                                        | 0/17 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.45002453463772935, 'accuracy': 0.8770949720670391, 'f1_score': 0.8602818204462157, 'roc_auc': 0.6763218390804597}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|█▊                             | 1/17 [01:44<27:49, 104.37s/it]\u001b[A\n",
      "Iteration:  12%|███▋                           | 2/17 [03:28<26:04, 104.32s/it]\u001b[A\n",
      "Iteration:  18%|█████▍                         | 3/17 [05:14<24:25, 104.66s/it]\u001b[A\n",
      "Iteration:  24%|███████▎                       | 4/17 [06:59<22:41, 104.76s/it]\u001b[A\n",
      "Iteration:  29%|█████████                      | 5/17 [08:45<21:01, 105.15s/it]\u001b[A\n",
      "Iteration:  35%|██████████▉                    | 6/17 [10:31<19:20, 105.46s/it]\u001b[A\n",
      "Iteration:  41%|████████████▊                  | 7/17 [12:19<17:42, 106.27s/it]\u001b[A\n",
      "Iteration:  47%|██████████████▌                | 8/17 [14:03<15:50, 105.62s/it]\u001b[A\n",
      "Iteration:  53%|████████████████▍              | 9/17 [15:51<14:11, 106.43s/it]\u001b[A\n",
      "Iteration:  59%|█████████████████▋            | 10/17 [17:40<12:30, 107.21s/it]\u001b[A\n",
      "Iteration:  65%|███████████████████▍          | 11/17 [19:29<10:45, 107.60s/it]\u001b[A\n",
      "Iteration:  71%|█████████████████████▏        | 12/17 [21:18<08:59, 107.97s/it]\u001b[A\n",
      "Iteration:  76%|██████████████████████▉       | 13/17 [23:06<07:12, 108.15s/it]\u001b[A\n",
      "Iteration:  82%|████████████████████████▋     | 14/17 [24:51<05:21, 107.07s/it]\u001b[A\n",
      "Iteration:  88%|██████████████████████████▍   | 15/17 [26:37<03:33, 106.72s/it]\u001b[A\n",
      "Iteration:  94%|████████████████████████████▏ | 16/17 [28:23<01:46, 106.45s/it]\u001b[A\n",
      "Iteration: 100%|██████████████████████████████| 17/17 [29:21<00:00, 103.63s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                       | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   8%|██▌                            | 1/12 [00:36<06:42, 36.60s/it]\u001b[A\n",
      "Evaluating:  17%|█████▏                         | 2/12 [01:15<06:13, 37.35s/it]\u001b[A\n",
      "Evaluating:  25%|███████▊                       | 3/12 [01:51<05:33, 37.03s/it]\u001b[A\n",
      "Evaluating:  33%|██████████▎                    | 4/12 [02:28<04:54, 36.82s/it]\u001b[A\n",
      "Evaluating:  42%|████████████▉                  | 5/12 [03:05<04:17, 36.79s/it]\u001b[A\n",
      "Evaluating:  50%|███████████████▌               | 6/12 [03:41<03:40, 36.78s/it]\u001b[A\n",
      "Evaluating:  58%|██████████████████             | 7/12 [04:18<03:03, 36.71s/it]\u001b[A\n",
      "Evaluating:  67%|████████████████████▋          | 8/12 [04:55<02:26, 36.70s/it]\u001b[A\n",
      "Evaluating:  75%|███████████████████████▎       | 9/12 [05:31<01:49, 36.64s/it]\u001b[A\n",
      "Evaluating:  83%|█████████████████████████     | 10/12 [06:07<01:12, 36.50s/it]\u001b[A\n",
      "Evaluating:  92%|███████████████████████████▌  | 11/12 [06:44<00:36, 36.47s/it]\u001b[A\n",
      "Evaluating: 100%|██████████████████████████████| 12/12 [06:51<00:00, 34.28s/it]\u001b[A\n",
      "Epoch:  73%|█████████████████████▊        | 8/11 [5:11:53<1:52:38, 2252.97s/it]\n",
      "Iteration:   0%|                                        | 0/17 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.4787951971714695, 'accuracy': 0.88268156424581, 'f1_score': 0.8710275744589123, 'roc_auc': 0.707471264367816}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|█▊                             | 1/17 [01:41<27:11, 101.94s/it]\u001b[A\n",
      "Iteration:  12%|███▋                           | 2/17 [03:29<25:55, 103.67s/it]\u001b[A\n",
      "Iteration:  18%|█████▍                         | 3/17 [05:15<24:19, 104.23s/it]\u001b[A\n",
      "Iteration:  24%|███████▎                       | 4/17 [07:00<22:37, 104.45s/it]\u001b[A\n",
      "Iteration:  29%|█████████                      | 5/17 [08:48<21:08, 105.69s/it]\u001b[A\n",
      "Iteration:  35%|██████████▉                    | 6/17 [10:34<19:21, 105.57s/it]\u001b[A\n",
      "Iteration:  41%|████████████▊                  | 7/17 [12:22<17:45, 106.53s/it]\u001b[A\n",
      "Iteration:  47%|██████████████▌                | 8/17 [14:11<16:04, 107.17s/it]\u001b[A\n",
      "Iteration:  53%|████████████████▍              | 9/17 [15:59<14:20, 107.52s/it]\u001b[A\n",
      "Iteration:  59%|█████████████████▋            | 10/17 [17:47<12:32, 107.54s/it]\u001b[A\n",
      "Iteration:  65%|███████████████████▍          | 11/17 [19:34<10:44, 107.46s/it]\u001b[A\n",
      "Iteration:  71%|█████████████████████▏        | 12/17 [21:19<08:52, 106.58s/it]\u001b[A\n",
      "Iteration:  76%|██████████████████████▉       | 13/17 [23:04<07:04, 106.08s/it]\u001b[A\n",
      "Iteration:  82%|████████████████████████▋     | 14/17 [24:49<05:18, 106.03s/it]\u001b[A\n",
      "Iteration:  88%|██████████████████████████▍   | 15/17 [26:34<03:31, 105.72s/it]\u001b[A\n",
      "Iteration:  94%|████████████████████████████▏ | 16/17 [28:20<01:45, 105.53s/it]\u001b[A\n",
      "Iteration: 100%|██████████████████████████████| 17/17 [29:23<00:00, 103.71s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                       | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   8%|██▌                            | 1/12 [00:37<06:54, 37.73s/it]\u001b[A\n",
      "Evaluating:  17%|█████▏                         | 2/12 [01:16<06:20, 38.03s/it]\u001b[A\n",
      "Evaluating:  25%|███████▊                       | 3/12 [01:55<05:45, 38.43s/it]\u001b[A\n",
      "Evaluating:  33%|██████████▎                    | 4/12 [02:33<05:06, 38.34s/it]\u001b[A\n",
      "Evaluating:  42%|████████████▉                  | 5/12 [03:14<04:32, 38.96s/it]\u001b[A\n",
      "Evaluating:  50%|███████████████▌               | 6/12 [03:53<03:53, 38.91s/it]\u001b[A\n",
      "Evaluating:  58%|██████████████████             | 7/12 [04:32<03:15, 39.14s/it]\u001b[A\n",
      "Evaluating:  67%|████████████████████▋          | 8/12 [05:11<02:36, 39.11s/it]\u001b[A\n",
      "Evaluating:  75%|███████████████████████▎       | 9/12 [05:50<01:56, 38.85s/it]\u001b[A\n",
      "Evaluating:  83%|█████████████████████████     | 10/12 [06:28<01:17, 38.60s/it]\u001b[A\n",
      "Evaluating:  92%|███████████████████████████▌  | 11/12 [07:06<00:38, 38.40s/it]\u001b[A\n",
      "Evaluating: 100%|██████████████████████████████| 12/12 [07:13<00:00, 36.13s/it]\u001b[A\n",
      "Epoch:  82%|████████████████████████▌     | 9/11 [5:48:31<1:14:33, 2236.63s/it]\n",
      "Iteration:   0%|                                        | 0/17 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.503812527594467, 'accuracy': 0.8770949720670391, 'f1_score': 0.8602818204462157, 'roc_auc': 0.6763218390804597}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|█▊                             | 1/17 [02:00<32:05, 120.34s/it]\u001b[A\n",
      "Iteration:  12%|███▋                           | 2/17 [03:48<29:08, 116.56s/it]\u001b[A\n",
      "Iteration:  18%|█████▍                         | 3/17 [05:41<26:56, 115.45s/it]\u001b[A\n",
      "Iteration:  24%|███████▎                       | 4/17 [07:42<25:23, 117.21s/it]\u001b[A\n",
      "Iteration:  29%|█████████                      | 5/17 [09:57<24:27, 122.29s/it]\u001b[A\n",
      "Iteration:  35%|██████████▉                    | 6/17 [12:11<23:06, 126.02s/it]\u001b[A\n",
      "Iteration:  41%|████████████▊                  | 7/17 [14:10<20:38, 123.88s/it]\u001b[A\n",
      "Iteration:  47%|██████████████▌                | 8/17 [16:13<18:32, 123.62s/it]\u001b[A\n",
      "Iteration:  53%|████████████████▍              | 9/17 [18:36<17:15, 129.41s/it]\u001b[A\n",
      "Iteration:  59%|█████████████████▋            | 10/17 [20:59<15:33, 133.42s/it]\u001b[A\n",
      "Iteration:  65%|███████████████████▍          | 11/17 [23:06<13:09, 131.57s/it]\u001b[A\n",
      "Iteration:  71%|█████████████████████▏        | 12/17 [25:27<11:12, 134.42s/it]\u001b[A\n",
      "Iteration:  76%|██████████████████████▉       | 13/17 [27:58<09:14, 138.55s/it]\u001b[A\n",
      "Iteration:  82%|████████████████████████▋     | 14/17 [30:19<07:00, 140.17s/it]\u001b[A\n",
      "Iteration:  88%|██████████████████████████▍   | 15/17 [32:23<04:30, 135.30s/it]\u001b[A\n",
      "Iteration:  94%|████████████████████████████▏ | 16/17 [34:49<02:18, 138.47s/it]\u001b[A\n",
      "Iteration: 100%|██████████████████████████████| 17/17 [35:52<00:00, 126.62s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                       | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   8%|██▌                            | 1/12 [00:37<06:57, 37.97s/it]\u001b[A\n",
      "Evaluating:  17%|█████▏                         | 2/12 [01:15<06:18, 37.89s/it]\u001b[A\n",
      "Evaluating:  25%|███████▊                       | 3/12 [01:52<05:38, 37.56s/it]\u001b[A\n",
      "Evaluating:  33%|██████████▎                    | 4/12 [02:30<05:02, 37.81s/it]\u001b[A\n",
      "Evaluating:  42%|████████████▉                  | 5/12 [03:09<04:26, 38.01s/it]\u001b[A\n",
      "Evaluating:  50%|███████████████▌               | 6/12 [03:46<03:46, 37.67s/it]\u001b[A\n",
      "Evaluating:  58%|██████████████████             | 7/12 [04:22<03:06, 37.38s/it]\u001b[A\n",
      "Evaluating:  67%|████████████████████▋          | 8/12 [04:59<02:28, 37.15s/it]\u001b[A\n",
      "Evaluating:  75%|███████████████████████▎       | 9/12 [05:42<01:56, 39.00s/it]\u001b[A\n",
      "Evaluating:  83%|█████████████████████████     | 10/12 [06:25<01:20, 40.23s/it]\u001b[A\n",
      "Evaluating:  92%|███████████████████████████▌  | 11/12 [07:11<00:41, 41.94s/it]\u001b[A\n",
      "Evaluating: 100%|██████████████████████████████| 12/12 [07:21<00:00, 36.80s/it]\u001b[A\n",
      "Epoch:  91%|████████████████████████████▏  | 10/11 [6:31:48<39:04, 2344.67s/it]\n",
      "Iteration:   0%|                                        | 0/17 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.46619628990689915, 'accuracy': 0.8770949720670391, 'f1_score': 0.8753072097165479, 'roc_auc': 0.7597701149425289}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|█▊                             | 1/17 [02:06<33:40, 126.25s/it]\u001b[A\n",
      "Iteration:  12%|███▋                           | 2/17 [04:41<33:40, 134.69s/it]\u001b[A\n",
      "Iteration:  18%|█████▍                         | 3/17 [07:00<31:46, 136.19s/it]\u001b[A\n",
      "Iteration:  24%|███████▎                       | 4/17 [09:05<28:44, 132.65s/it]\u001b[A\n",
      "Iteration:  29%|█████████                      | 5/17 [11:24<26:55, 134.60s/it]\u001b[A\n",
      "Iteration:  35%|██████████▉                    | 6/17 [13:49<25:13, 137.63s/it]\u001b[A\n",
      "Iteration:  41%|████████████▊                  | 7/17 [15:44<21:48, 130.88s/it]\u001b[A\n",
      "Iteration:  47%|██████████████▌                | 8/17 [17:39<18:56, 126.23s/it]\u001b[A\n",
      "Iteration:  53%|████████████████▍              | 9/17 [19:55<17:12, 129.07s/it]\u001b[A\n",
      "Iteration:  59%|█████████████████▋            | 10/17 [22:05<15:06, 129.43s/it]\u001b[A\n",
      "Iteration:  65%|███████████████████▍          | 11/17 [24:26<13:16, 132.74s/it]\u001b[A\n",
      "Iteration:  71%|█████████████████████▏        | 12/17 [26:51<11:23, 136.64s/it]\u001b[A\n",
      "Iteration:  76%|██████████████████████▉       | 13/17 [29:03<09:00, 135.08s/it]\u001b[A\n",
      "Iteration:  82%|████████████████████████▋     | 14/17 [31:27<06:53, 137.70s/it]\u001b[A\n",
      "Iteration:  88%|██████████████████████████▍   | 15/17 [34:05<04:47, 143.98s/it]\u001b[A\n",
      "Iteration:  94%|████████████████████████████▏ | 16/17 [36:44<02:28, 148.28s/it]\u001b[A\n",
      "Iteration: 100%|██████████████████████████████| 17/17 [37:54<00:00, 133.77s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                       | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   8%|██▌                            | 1/12 [00:43<07:57, 43.40s/it]\u001b[A\n",
      "Evaluating:  17%|█████▏                         | 2/12 [01:25<07:10, 43.05s/it]\u001b[A\n",
      "Evaluating:  25%|███████▊                       | 3/12 [02:08<06:27, 43.04s/it]\u001b[A\n",
      "Evaluating:  33%|██████████▎                    | 4/12 [02:50<05:42, 42.75s/it]\u001b[A\n",
      "Evaluating:  42%|████████████▉                  | 5/12 [03:31<04:54, 42.05s/it]\u001b[A\n",
      "Evaluating:  50%|███████████████▌               | 6/12 [04:13<04:12, 42.12s/it]\u001b[A\n",
      "Evaluating:  58%|██████████████████             | 7/12 [04:59<03:36, 43.31s/it]\u001b[A\n",
      "Evaluating:  67%|████████████████████▋          | 8/12 [05:43<02:53, 43.49s/it]\u001b[A\n",
      "Evaluating:  75%|███████████████████████▎       | 9/12 [06:27<02:10, 43.62s/it]\u001b[A\n",
      "Evaluating:  83%|█████████████████████████     | 10/12 [07:09<01:26, 43.28s/it]\u001b[A\n",
      "Evaluating:  92%|███████████████████████████▌  | 11/12 [07:49<00:42, 42.34s/it]\u001b[A\n",
      "Evaluating: 100%|██████████████████████████████| 12/12 [07:57<00:00, 39.81s/it]\u001b[A\n",
      "Epoch: 100%|███████████████████████████████| 11/11 [7:17:46<00:00, 2468.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.46982651265958947, 'accuracy': 0.8659217877094972, 'f1_score': 0.8659217877094972, 'roc_auc': 0.7531034482758621}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████| 11/11 [7:17:46<00:00, 2387.85s/it]\n"
     ]
    }
   ],
   "source": [
    "main_model = RBERT_re(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
