{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import logging\n",
    "import random\n",
    "import copy\n",
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer,AdamW, BertConfig, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertModel, BertPreTrainedModel\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = '../data/label.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "ADDITIONAL_SPECIAL_TOKENS = [\"<e1>\", \"</e1>\", \"<e2>\", \"</e2>\"]\n",
    "\n",
    "\n",
    "def get_label(args):\n",
    "    return [label.strip() for label in open(label_path, \"r\", encoding=\"utf-8\")]\n",
    "\n",
    "\n",
    "def load_tokenizer(args):\n",
    "    tokenizer = BertTokenizer.from_pretrained(args.model_name_or_path)\n",
    "    tokenizer.add_special_tokens({\"additional_special_tokens\": ADDITIONAL_SPECIAL_TOKENS})\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def write_prediction(args, output_file, preds):\n",
    "    \"\"\"\n",
    "    For official evaluation script\n",
    "    :param output_file: prediction_file_path (e.g. eval/proposed_answers.txt)\n",
    "    :param preds: [0,1,0,2,18,...]\n",
    "    \"\"\"\n",
    "    relation_labels = get_label(args)\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for idx, pred in enumerate(preds):\n",
    "            f.write(\"{}\\t{}\\n\".format(8001 + idx, relation_labels[pred]))\n",
    "\n",
    "\n",
    "def init_logger():\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO)\n",
    "\n",
    "\n",
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if not args.no_cuda and torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(preds, labels):\n",
    "    assert len(preds) == len(labels)\n",
    "    return acc(preds, labels)\n",
    "\n",
    "\n",
    "def simple_accuracy(preds, labels):\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "\n",
    "def acc(preds, labels, average=\"macro\"):\n",
    "    acc = simple_accuracy(preds, labels)\n",
    "    return {\n",
    "        \"acc\": acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils import get_label\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"\n",
    "    A single training/test example for simple sequence classification.\n",
    "    Args:\n",
    "        guid: Unique id for the example.\n",
    "        text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "        label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, label):\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.label = label\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.to_json_string())\n",
    "\n",
    "    def to_dict(self):\n",
    "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
    "        output = copy.deepcopy(self.__dict__)\n",
    "        return output\n",
    "\n",
    "    def to_json_string(self):\n",
    "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
    "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
    "\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"\n",
    "    A single set of features of data.\n",
    "    Args:\n",
    "        input_ids: Indices of input sequence tokens in the vocabulary.\n",
    "        attention_mask: Mask to avoid performing attention on padding token indices.\n",
    "            Mask values selected in ``[0, 1]``:\n",
    "            Usually  ``1`` for tokens that are NOT MASKED, ``0`` for MASKED (padded) tokens.\n",
    "        token_type_ids: Segment token indices to indicate first and second portions of the inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, attention_mask, token_type_ids, label_id, e1_mask, e2_mask):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.token_type_ids = token_type_ids\n",
    "        self.label_id = label_id\n",
    "        self.e1_mask = e1_mask\n",
    "        self.e2_mask = e2_mask\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.to_json_string())\n",
    "\n",
    "    def to_dict(self):\n",
    "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
    "        output = copy.deepcopy(self.__dict__)\n",
    "        return output\n",
    "\n",
    "    def to_json_string(self):\n",
    "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
    "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
    "\n",
    "\n",
    "class SemEvalProcessor(object):\n",
    "    \"\"\"Processor for the Semeval data set \"\"\"\n",
    "\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.relation_labels = get_label(args)\n",
    "\n",
    "    @classmethod\n",
    "    def _read_tsv(cls, input_file, quotechar=None):\n",
    "        \"\"\"Reads a tab separated value file.\"\"\"\n",
    "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
    "            lines = []\n",
    "            for line in reader:\n",
    "                lines.append(line)\n",
    "            return lines\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = line[0]\n",
    "            label = self.relation_labels.index(line[1])\n",
    "            if i % 1000 == 0:\n",
    "                logger.info(line)\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, label=label))\n",
    "        return examples\n",
    "\n",
    "\n",
    "    def get_examples(self, mode):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            mode: train, dev, test\n",
    "        \"\"\"\n",
    "        file_to_read = None\n",
    "        if mode == \"train_file\":\n",
    "            file_to_read = self.args.train_file\n",
    "        elif mode == \"eval_file\":\n",
    "            file_to_read = self.args.test_file\n",
    "        elif mode == \"test_file\":\n",
    "            file_to_read = self.args.test_file\n",
    "\n",
    "        logger.info(\"LOOKING AT {}\".format(os.path.join(self.args.data_dir, file_to_read)))\n",
    "        return self._create_examples(self._read_tsv(os.path.join(self.args.data_dir, file_to_read)), mode)\n",
    "\n",
    "\n",
    "processors = {\"semeval\": SemEvalProcessor}\n",
    "\n",
    "\n",
    "def read_examples_from_file(data_dir, mode):\n",
    "    file_path = os.path.join(data_dir, \"{}.txt\".format(mode))\n",
    "    guid_index = 1\n",
    "    examples = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            if len(line) == 2:\n",
    "                text_a = line[0]\n",
    "                label = line[1]\n",
    "            else:\n",
    "                text_a = line[0]\n",
    "                label = \"NONE\"\n",
    "            examples.append(InputExample(guid=guid_index, text_a=text_a, label=label))\n",
    "            guid_index += 1\n",
    "\n",
    "    return examples\n",
    "\n",
    "def convert_examples_to_features(\n",
    "    examples,\n",
    "    max_seq_len,\n",
    "    tokenizer,\n",
    "    cls_token=\"[CLS]\",\n",
    "    cls_token_segment_id=0,\n",
    "    sep_token=\"[SEP]\",\n",
    "    pad_token=0,\n",
    "    pad_token_segment_id=0,\n",
    "    sequence_a_segment_id=0,\n",
    "    add_sep_token=False,\n",
    "    mask_padding_with_zero=True,\n",
    "):\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        if ex_index % 5000 == 0:\n",
    "            logger.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
    "\n",
    "        tokens_a = tokenizer.tokenize(example.text_a)\n",
    "        print(tokens_a)\n",
    "\n",
    "        e11_p = tokens_a.index(\"<e1>\")  # the start position of entity1\n",
    "        e12_p = tokens_a.index(\"</e1>\")  # the end position of entity1\n",
    "        e21_p = tokens_a.index(\"<e2>\")  # the start position of entity2\n",
    "        e22_p = tokens_a.index(\"</e2>\")  # the end position of entity2\n",
    "\n",
    "        # Replace the token\n",
    "        tokens_a[e11_p] = \"$\"\n",
    "        tokens_a[e12_p] = \"$\"\n",
    "        tokens_a[e21_p] = \"#\"\n",
    "        tokens_a[e22_p] = \"#\"\n",
    "\n",
    "        # Add 1 because of the [CLS] token\n",
    "        e11_p += 1\n",
    "        e12_p += 1\n",
    "        e21_p += 1\n",
    "        e22_p += 1\n",
    "\n",
    "        # Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.\n",
    "        if add_sep_token:\n",
    "            special_tokens_count = 2\n",
    "        else:\n",
    "            special_tokens_count = 1\n",
    "        if len(tokens_a) > max_seq_len - special_tokens_count:\n",
    "            tokens_a = tokens_a[: (max_seq_len - special_tokens_count)]\n",
    "\n",
    "        tokens = tokens_a\n",
    "        if add_sep_token:\n",
    "            tokens += [sep_token]\n",
    "\n",
    "        token_type_ids = [sequence_a_segment_id] * len(tokens)\n",
    "\n",
    "        tokens = [cls_token] + tokens\n",
    "        token_type_ids = [cls_token_segment_id] + token_type_ids\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.\n",
    "        attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding_length = max_seq_len - len(input_ids)\n",
    "        input_ids = input_ids + ([pad_token] * padding_length)\n",
    "        attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)\n",
    "\n",
    "        # e1 mask, e2 mask\n",
    "        e1_mask = [0] * len(attention_mask)\n",
    "        e2_mask = [0] * len(attention_mask)\n",
    "\n",
    "        for i in range(e11_p, e12_p + 1):\n",
    "            e1_mask[i] = 1\n",
    "        for i in range(e21_p, e22_p + 1):\n",
    "            e2_mask[i] = 1\n",
    "\n",
    "        assert len(input_ids) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_ids), max_seq_len)\n",
    "        assert len(attention_mask) == max_seq_len, \"Error with attention mask length {} vs {}\".format(\n",
    "            len(attention_mask), max_seq_len\n",
    "        )\n",
    "        assert len(token_type_ids) == max_seq_len, \"Error with token type length {} vs {}\".format(\n",
    "            len(token_type_ids), max_seq_len\n",
    "        )\n",
    "\n",
    "        label_id = int(example.label)\n",
    "\n",
    "        if ex_index < 5:\n",
    "            logger.info(\"*** Example ***\")\n",
    "            logger.info(\"guid: %s\" % example.guid)\n",
    "            logger.info(\"tokens: %s\" % \" \".join([str(x) for x in tokens]))\n",
    "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "            logger.info(\"attention_mask: %s\" % \" \".join([str(x) for x in attention_mask]))\n",
    "            logger.info(\"token_type_ids: %s\" % \" \".join([str(x) for x in token_type_ids]))\n",
    "            logger.info(\"label: %s (id = %d)\" % (example.label, label_id))\n",
    "            logger.info(\"e1_mask: %s\" % \" \".join([str(x) for x in e1_mask]))\n",
    "            logger.info(\"e2_mask: %s\" % \" \".join([str(x) for x in e2_mask]))\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "                label_id=label_id,\n",
    "                e1_mask=e1_mask,\n",
    "                e2_mask=e2_mask,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def load_and_cache_examples(args, tokenizer, mode):\n",
    "    processor = processors[args.task](args)\n",
    "\n",
    "    # Load data features from cache or dataset file\n",
    "    cached_features_file = os.path.join(\n",
    "        args.data_dir,\n",
    "        \"cached_{}_{}_{}_{}\".format(\n",
    "            mode,\n",
    "            args.task,\n",
    "            list(filter(None, args.model_name_or_path.split(\"/\"))).pop(),\n",
    "            args.max_seq_len,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    if os.path.exists(cached_features_file):\n",
    "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
    "        features = torch.load(cached_features_file)\n",
    "    else:\n",
    "        logger.info(\"Creating features from dataset file at %s\", args.data_dir)\n",
    "        if mode == \"train_file\":\n",
    "            examples = processor.get_examples(\"train_file\")\n",
    "        elif mode == \"eval_file\":\n",
    "            examples = processor.get_examples(\"eval_file\")\n",
    "        elif mode == \"test_file\":\n",
    "            examples = processor.get_examples(\"test_file\")\n",
    "        else:\n",
    "            raise Exception(\"For mode, Only train, dev, test is available\")\n",
    "\n",
    "        features = convert_examples_to_features(\n",
    "            examples, args.max_seq_len, tokenizer\n",
    "        )\n",
    "        logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
    "        torch.save(features, cached_features_file)\n",
    "\n",
    "    # Convert to Tensors and build dataset\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
    "    all_token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long)\n",
    "    all_e1_mask = torch.tensor([f.e1_mask for f in features], dtype=torch.long)  # add e1 mask\n",
    "    all_e2_mask = torch.tensor([f.e2_mask for f in features], dtype=torch.long)  # add e2 mask\n",
    "\n",
    "    all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "\n",
    "    dataset = TensorDataset(\n",
    "        all_input_ids,\n",
    "        all_attention_mask,\n",
    "        all_token_type_ids,\n",
    "        all_label_ids,\n",
    "        all_e1_mask,\n",
    "        all_e2_mask,\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.0, use_activation=True):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self.use_activation = use_activation\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        if self.use_activation:\n",
    "            x = self.tanh(x)\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class RBERT(BertPreTrainedModel):\n",
    "    def __init__(self, config, args):\n",
    "        super(RBERT, self).__init__(config)\n",
    "        self.bert = BertModel(config=config)  # Load pretrained bert\n",
    "\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.cls_fc_layer = FCLayer(config.hidden_size, config.hidden_size, args.dropout_rate)\n",
    "        self.entity_fc_layer = FCLayer(config.hidden_size, config.hidden_size, args.dropout_rate)\n",
    "        self.label_classifier = FCLayer(\n",
    "            config.hidden_size * 3,\n",
    "            config.num_labels,\n",
    "            args.dropout_rate,\n",
    "            use_activation=False,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def entity_average(hidden_output, e_mask):\n",
    "        \"\"\"\n",
    "        Average the entity hidden state vectors (H_i ~ H_j)\n",
    "        :param hidden_output: [batch_size, j-i+1, dim]\n",
    "        :param e_mask: [batch_size, max_seq_len]\n",
    "                e.g. e_mask[0] == [0, 0, 0, 1, 1, 1, 0, 0, ... 0]\n",
    "        :return: [batch_size, dim]\n",
    "        \"\"\"\n",
    "        e_mask_unsqueeze = e_mask.unsqueeze(1)  # [b, 1, j-i+1]\n",
    "        length_tensor = (e_mask != 0).sum(dim=1).unsqueeze(1)  # [batch_size, 1]\n",
    "\n",
    "        # [b, 1, j-i+1] * [b, j-i+1, dim] = [b, 1, dim] -> [b, dim]\n",
    "        sum_vector = torch.bmm(e_mask_unsqueeze.float(), hidden_output).squeeze(1)\n",
    "        avg_vector = sum_vector.float() / length_tensor.float()  # broadcasting\n",
    "        return avg_vector\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, labels, e1_mask, e2_mask):\n",
    "        outputs = self.bert(\n",
    "            input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids\n",
    "        )  # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        sequence_output = outputs[0]\n",
    "        pooled_output = outputs[1]  # [CLS]\n",
    "\n",
    "        # Average\n",
    "        e1_h = self.entity_average(sequence_output, e1_mask)\n",
    "        e2_h = self.entity_average(sequence_output, e2_mask)\n",
    "\n",
    "        # Dropout -> tanh -> fc_layer (Share FC layer for e1 and e2)\n",
    "        pooled_output = self.cls_fc_layer(pooled_output)\n",
    "        e1_h = self.entity_fc_layer(e1_h)\n",
    "        e2_h = self.entity_fc_layer(e2_h)\n",
    "\n",
    "        # Concat -> fc_layer\n",
    "        concat_h = torch.cat([pooled_output, e1_h, e2_h], dim=-1)\n",
    "        logits = self.label_classifier(concat_h)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "\n",
    "        # Softmax\n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                loss_fct = nn.MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = nn.CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), logits, (hidden_states), (attentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device(pred_config):\n",
    "    return \"cuda\" if torch.cuda.is_available() and not pred_config.no_cuda else \"cpu\"\n",
    "\n",
    "def convert_input_file_to_tensor_dataset(\n",
    "    args,\n",
    "    cls_token_segment_id=0,\n",
    "    pad_token_segment_id=0,\n",
    "    sequence_a_segment_id=0,\n",
    "    mask_padding_with_zero=True):\n",
    "    tokenizer = load_tokenizer(args)\n",
    "\n",
    "    # Setting based on the current model type\n",
    "    cls_token = tokenizer.cls_token\n",
    "    sep_token = tokenizer.sep_token\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    all_input_ids = []\n",
    "    all_attention_mask = []\n",
    "    all_token_type_ids = []\n",
    "    all_e1_mask = []\n",
    "    all_e2_mask = []\n",
    "\n",
    "    with open(args.input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            tokens = tokenizer.tokenize(line)\n",
    "\n",
    "            e11_p = tokens.index(\"<e1>\")  # the start position of entity1\n",
    "            e12_p = tokens.index(\"</e1>\")  # the end position of entity1\n",
    "            e21_p = tokens.index(\"<e2>\")  # the start position of entity2\n",
    "            e22_p = tokens.index(\"</e2>\")  # the end position of entity2\n",
    "\n",
    "            # Replace the token\n",
    "            tokens[e11_p] = \"$\"\n",
    "            tokens[e12_p] = \"$\"\n",
    "            tokens[e21_p] = \"#\"\n",
    "            tokens[e22_p] = \"#\"\n",
    "\n",
    "            # Add 1 because of the [CLS] token\n",
    "            e11_p += 1\n",
    "            e12_p += 1\n",
    "            e21_p += 1\n",
    "            e22_p += 1\n",
    "\n",
    "            # Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.\n",
    "            if args.add_sep_token:\n",
    "                special_tokens_count = 2\n",
    "            else:\n",
    "                special_tokens_count = 1\n",
    "            if len(tokens) > args.max_seq_len - special_tokens_count:\n",
    "                tokens = tokens[: (args.max_seq_len - special_tokens_count)]\n",
    "\n",
    "            # Add [SEP] token\n",
    "            if args.add_sep_token:\n",
    "                tokens += [sep_token]\n",
    "            token_type_ids = [sequence_a_segment_id] * len(tokens)\n",
    "\n",
    "            # Add [CLS] token\n",
    "            tokens = [cls_token] + tokens\n",
    "            token_type_ids = [cls_token_segment_id] + token_type_ids\n",
    "\n",
    "            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "            # The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.\n",
    "            attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "            # Zero-pad up to the sequence length.\n",
    "            padding_length = args.max_seq_len - len(input_ids)\n",
    "            input_ids = input_ids + ([pad_token_id] * padding_length)\n",
    "            attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "            token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)\n",
    "\n",
    "            # e1 mask, e2 mask\n",
    "            e1_mask = [0] * len(attention_mask)\n",
    "            e2_mask = [0] * len(attention_mask)\n",
    "\n",
    "            for i in range(e11_p, e12_p + 1):\n",
    "                e1_mask[i] = 1\n",
    "            for i in range(e21_p, e22_p + 1):\n",
    "                e2_mask[i] = 1\n",
    "\n",
    "            all_input_ids.append(input_ids)\n",
    "            all_attention_mask.append(attention_mask)\n",
    "            all_token_type_ids.append(token_type_ids)\n",
    "            all_e1_mask.append(e1_mask)\n",
    "            all_e2_mask.append(e2_mask)\n",
    "\n",
    "    # Change to Tensor\n",
    "    all_input_ids = torch.tensor(all_input_ids, dtype=torch.long)\n",
    "    all_attention_mask = torch.tensor(all_attention_mask, dtype=torch.long)\n",
    "    all_token_type_ids = torch.tensor(all_token_type_ids, dtype=torch.long)\n",
    "    all_e1_mask = torch.tensor(all_e1_mask, dtype=torch.long)\n",
    "    all_e2_mask = torch.tensor(all_e2_mask, dtype=torch.long)\n",
    "\n",
    "    dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_e1_mask, all_e2_mask)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self, args, train_dataset=None, dev_dataset=None, test_dataset=None):\n",
    "        self.args = args\n",
    "        self.train_dataset = train_dataset\n",
    "        self.dev_dataset = dev_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "\n",
    "        self.label_lst = get_label(args)\n",
    "        self.num_labels = len(self.label_lst)\n",
    "\n",
    "        self.config = BertConfig.from_pretrained(\n",
    "            args.model_name_or_path,\n",
    "            num_labels=self.num_labels,\n",
    "            finetuning_task=args.task,\n",
    "            id2label={str(i): label for i, label in enumerate(self.label_lst)},\n",
    "            label2id={label: i for i, label in enumerate(self.label_lst)},\n",
    "        )\n",
    "        self.model = RBERT.from_pretrained(args.model_name_or_path, config=self.config, args=args)\n",
    "\n",
    "        # GPU or CPU\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        \n",
    "    def evaluate(self, mode):\n",
    "        # We use test dataset because semeval doesn't have dev dataset\n",
    "        if mode == \"test\":\n",
    "            dataset = self.test_dataset\n",
    "        elif mode == \"dev\":\n",
    "            dataset = self.dev_dataset\n",
    "        else:\n",
    "            raise Exception(\"Only dev and test dataset available\")\n",
    "\n",
    "        eval_sampler = SequentialSampler(dataset)\n",
    "        eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=self.args.eval_batch_size)\n",
    "        # Eval!\n",
    "\n",
    "        eval_loss = 0.0\n",
    "        nb_eval_steps = 0\n",
    "        preds = None\n",
    "        out_label_ids = None\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "            batch = tuple(t.to(self.device) for t in batch)\n",
    "            with torch.no_grad():\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"token_type_ids\": batch[2],\n",
    "                    \"labels\": batch[3],\n",
    "                    \"e1_mask\": batch[4],\n",
    "                    \"e2_mask\": batch[5],\n",
    "                }\n",
    "                outputs = self.model(**inputs)\n",
    "                tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "                eval_loss += tmp_eval_loss.mean().item()\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "            if preds is None:\n",
    "                preds = logits.detach().cpu().numpy()\n",
    "                out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
    "            else:\n",
    "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "                out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "        eval_loss = eval_loss / nb_eval_steps\n",
    "        #results = {\"loss\": eval_loss}\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        write_prediction(self.args, os.path.join(self.args.eval_dir, \"proposed_answers_multilingual.txt\"), preds)\n",
    "\n",
    "        results = {\"loss\": eval_loss, 'accuracy' : accuracy_score(out_label_ids, preds), \n",
    "                   'f1_score': f1_score(out_label_ids, preds, average='weighted'),\n",
    "                  'roc_auc': roc_auc_score(out_label_ids, preds)}\n",
    "\n",
    "          #result = compute_metrics(preds, out_label_ids)\n",
    "          #results.update(result)\n",
    "\n",
    "        logger.info(\"***** Eval results *****\")\n",
    "        for key in sorted(results.keys()):\n",
    "            logger.info(\"  {} = {:.4f}\".format(key, results[key]))\n",
    "\n",
    "        return results\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        train_sampler = RandomSampler(self.train_dataset)\n",
    "        train_dataloader = DataLoader(\n",
    "            self.train_dataset,\n",
    "            sampler=train_sampler,\n",
    "            batch_size=self.args.train_batch_size,\n",
    "        )\n",
    "\n",
    "        if self.args.max_steps > 0:\n",
    "            t_total = self.args.max_steps\n",
    "            self.args.num_train_epochs = (\n",
    "                self.args.max_steps // (len(train_dataloader) // self.args.gradient_accumulation_steps) + 1\n",
    "            )\n",
    "        else:\n",
    "            t_total = len(train_dataloader) // self.args.gradient_accumulation_steps * self.args.num_train_epochs\n",
    "\n",
    "        # Prepare optimizer and schedule (linear warmup and decay)\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": self.args.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=self.args.learning_rate,\n",
    "            eps=self.args.adam_epsilon,\n",
    "        )\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.args.warmup_steps,\n",
    "            num_training_steps=t_total,\n",
    "        )\n",
    "        # Train!\n",
    "\n",
    "        global_step = 0\n",
    "        tr_loss = 0.0\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        train_iterator = trange(int(self.args.num_train_epochs), desc=\"Epoch\")\n",
    "\n",
    "        for _ in train_iterator:\n",
    "            epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "            for step, batch in enumerate(epoch_iterator):\n",
    "                self.model.train()\n",
    "                batch = tuple(t.to(self.device) for t in batch)  # GPU or CPU\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"token_type_ids\": batch[2],\n",
    "                    \"labels\": batch[3],\n",
    "                    \"e1_mask\": batch[4],\n",
    "                    \"e2_mask\": batch[5],\n",
    "                }\n",
    "                outputs = self.model(**inputs)\n",
    "                loss = outputs[0]\n",
    "\n",
    "                if self.args.gradient_accumulation_steps > 1:\n",
    "                    loss = loss / self.args.gradient_accumulation_steps\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                tr_loss += loss.item()\n",
    "                if (step + 1) % self.args.gradient_accumulation_steps == 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.args.max_grad_norm)\n",
    "\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()  # Update learning rate schedule\n",
    "                    self.model.zero_grad()\n",
    "                    global_step += 1\n",
    "\n",
    "            print(\"\\n====Evaluation====\")\n",
    "            print(\"\\nEvaluation: \", self.evaluate(\"test\"))\n",
    "            \n",
    "        self.save_model(self.model)\n",
    "\n",
    "    def save_model(self, model):\n",
    "        torch.save(model.state_dict(), 'model/model_multilingual_1105.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_model(args):\n",
    "    config = BertConfig.from_pretrained(args.model_name_or_path, num_labels = args.num_labels)\n",
    "    model = RBERT.from_pretrained('model/model_multilingual_1105.bin', config=config, args=args)\n",
    "    model.to(\"cpu\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict(pred_config):\n",
    "        device = \"cpu\"\n",
    "        model = load_saved_model(pred_config)\n",
    "        tokenizer = load_tokenizer(pred_config)\n",
    "\n",
    "        # Convert input file to TensorDataset\n",
    "        dataset = convert_input_file_to_tensor_dataset(pred_config)\n",
    "        #dataset = pred_config.input_file\n",
    "        # Predict\n",
    "        sampler = SequentialSampler(dataset)\n",
    "        data_loader = DataLoader(dataset, sampler=sampler, batch_size=pred_config.batch_size)\n",
    "\n",
    "        preds = None\n",
    "        \n",
    "        \n",
    "        for batch in tqdm(data_loader, desc=\"Predicting\"):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            with torch.no_grad():\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"token_type_ids\": batch[2],\n",
    "                    \"labels\": None,\n",
    "                    \"e1_mask\": batch[3],\n",
    "                    \"e2_mask\": batch[4],\n",
    "                }\n",
    "                outputs = model(**inputs)\n",
    "                logits = outputs[0]\n",
    "\n",
    "                if preds is None:\n",
    "                    preds = logits.detach().cpu().numpy()\n",
    "                else:\n",
    "                    preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "\n",
    "        # Write to output file\n",
    "        label_lst = get_label(pred_config)\n",
    "        with open(pred_config.output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            for pred in preds:\n",
    "                f.write(\"{}\\n\".format(label_lst[pred]))\n",
    "\n",
    "        print('Prediction was done')\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pred_config):\n",
    "    # We use test dataset because semeval doesn't have dev dataset\n",
    "    device = \"cpu\"\n",
    "    model = load_saved_model(pred_config)\n",
    "    tokenizer = load_tokenizer(pred_config)\n",
    "    dataset = convert_input_file_to_tensor_dataset(pred_config)\n",
    "\n",
    "    eval_sampler = SequentialSampler(dataset)\n",
    "    eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=pred_config.batch_size)\n",
    "    # Eval!\n",
    "\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "\n",
    "\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Predicting\"):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        with torch.no_grad():\n",
    "            inputs = {\n",
    "                \"input_ids\": batch[0],\n",
    "                \"attention_mask\": batch[1],\n",
    "                \"token_type_ids\": batch[2],\n",
    "                \"labels\": None,\n",
    "                \"e1_mask\": batch[3],\n",
    "                \"e2_mask\": batch[4],\n",
    "            }\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs[0]\n",
    "\n",
    "\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "        if preds is None:\n",
    "            preds = logits.detach().cpu().numpy()\n",
    "            #out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            #out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "\n",
    "    #results = {\"loss\": eval_loss}\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    \n",
    "#     results = {'accuracy' : accuracy_score(out_label_ids, preds), \n",
    "#                'f1_score': f1_score(out_label_ids, preds, average='weighted'),\n",
    "#               'roc_auc': roc_auc_score(out_label_ids, preds)}\n",
    "\n",
    "      #result = compute_metrics(preds, out_label_ids)\n",
    "      #results.update(result)\n",
    "\n",
    "#     logger.info(\"***** Eval results *****\")\n",
    "#     for key in sorted(results.keys()):\n",
    "#         logger.info(\"  {} = {:.4f}\".format(key, results[key]))\n",
    "\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBERT_re(args):\n",
    "    set_seed(args)\n",
    "    tokenizer = load_tokenizer(args)\n",
    "\n",
    "    train_dataset = load_and_cache_examples(args, tokenizer, mode=\"train_file\")\n",
    "    test_dataset = load_and_cache_examples(args, tokenizer, mode=\"eval_file\")\n",
    "\n",
    "    trainer = Trainer(args, train_dataset=train_dataset, test_dataset=test_dataset)\n",
    "\n",
    "\n",
    "    if args.do_train:\n",
    "        trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer_args(object):\n",
    "    def __init__(self,\n",
    "                model_name_or_path = 'bert-base-multilingual-cased',\n",
    "                seed = 24,\n",
    "                task = \"semeval\",\n",
    "                train_file = 'train_balanced.csv', \n",
    "                test_file = 'eval_balanced.csv',\n",
    "                label_file = 'label.txt',  \n",
    "                dropout_rate = 0.1,\n",
    "                num_labels = 2,\n",
    "                learning_rate = 2e-5,\n",
    "                num_train_epochs = 22,\n",
    "                max_seq_len = 384,\n",
    "                train_batch_size = 16,\n",
    "                eval_batch_size = 16,\n",
    "                adam_epsilon = 1e-8,\n",
    "                gradient_accumulation_steps = 1,\n",
    "                max_grad_norm = 1.0,\n",
    "                logging_steps = 250,\n",
    "                save_steps = 250,\n",
    "                weight_decay = 0.0,\n",
    "                add_sep_token = True,\n",
    "                do_train = True,\n",
    "                no_cuda = True,\n",
    "                do_eval = True,\n",
    "                max_steps = -1,\n",
    "                warmup_steps = 0,\n",
    "                model_dir = 'model/',\n",
    "                data_dir = '../data/',\n",
    "                eval_dir = '../data/'\n",
    "                ):\n",
    "\n",
    "        super(Trainer_args, self).__init__()\n",
    "\n",
    "        self.train_file = train_file\n",
    "        self.test_file = test_file\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.num_labels = num_labels\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_train_epochs = num_train_epochs\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.adam_epsilon = adam_epsilon\n",
    "        self.gradient_accumulation_steps = gradient_accumulation_steps\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        self.logging_steps = logging_steps\n",
    "        self.save_steps = save_steps\n",
    "        self.weight_decay = weight_decay\n",
    "        self.data_dir = data_dir\n",
    "        self.model_name_or_path = model_name_or_path\n",
    "        self.seed = seed\n",
    "        self.task = task\n",
    "        self.add_sep_token = add_sep_token\n",
    "        self.do_train = do_train\n",
    "        self.no_cuda = no_cuda\n",
    "        self.max_steps = max_steps\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.model_dir = model_dir\n",
    "        self.label_file = label_file\n",
    "        self.eval_batch_size = eval_batch_size\n",
    "        self.do_eval = do_eval\n",
    "        self.eval_dir = eval_dir\n",
    "        return \n",
    "args = Trainer_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../data/train_balanced.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing RBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing RBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RBERT were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['cls_fc_layer.linear.weight', 'cls_fc_layer.linear.bias', 'entity_fc_layer.linear.weight', 'entity_fc_layer.linear.bias', 'label_classifier.linear.weight', 'label_classifier.linear.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   0%|                                            | 0/22 [00:00<?, ?it/s]\n",
      "Iteration:   0%|                                         | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  11%|███▌                            | 1/9 [02:02<16:14, 121.81s/it]\u001b[A\n",
      "Iteration:  22%|███████                         | 2/9 [04:25<14:56, 128.12s/it]\u001b[A\n",
      "Iteration:  33%|██████████▋                     | 3/9 [06:35<12:52, 128.67s/it]\u001b[A\n",
      "Iteration:  44%|██████████████▏                 | 4/9 [08:35<10:31, 126.35s/it]\u001b[A\n",
      "Iteration:  56%|█████████████████▊              | 5/9 [10:45<08:29, 127.40s/it]\u001b[A\n",
      "Iteration:  67%|█████████████████████▎          | 6/9 [12:51<06:21, 127.05s/it]\u001b[A\n",
      "Iteration:  78%|████████████████████████▉       | 7/9 [14:56<04:12, 126.44s/it]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▍   | 8/9 [17:06<02:07, 127.29s/it]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 9/9 [18:29<00:00, 123.33s/it]\u001b[A\n",
      "\n",
      "Evaluating:   0%|                                        | 0/8 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:  12%|████                            | 1/8 [00:40<04:44, 40.68s/it]\u001b[A\n",
      "Evaluating:  25%|████████                        | 2/8 [01:21<04:04, 40.67s/it]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 3/8 [02:02<03:23, 40.69s/it]\u001b[A\n",
      "Evaluating:  50%|████████████████                | 4/8 [02:42<02:42, 40.67s/it]\u001b[A\n",
      "Evaluating:  62%|████████████████████            | 5/8 [03:23<02:01, 40.63s/it]\u001b[A\n",
      "Evaluating:  75%|████████████████████████        | 6/8 [04:03<01:21, 40.67s/it]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████    | 7/8 [04:44<00:40, 40.73s/it]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 8/8 [05:13<00:00, 39.17s/it]\u001b[A\n",
      "Epoch:   5%|█▍                              | 1/22 [23:44<8:18:31, 1424.35s/it]\n",
      "Iteration:   0%|                                         | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.6818543449044228, 'accuracy': 0.5853658536585366, 'f1_score': 0.6247049567269867, 'roc_auc': 0.6950757575757576}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███▌                            | 1/9 [01:58<15:49, 118.72s/it]\u001b[A\n",
      "Iteration:  22%|███████                         | 2/9 [04:02<14:01, 120.27s/it]\u001b[A\n",
      "Iteration:  33%|██████████▋                     | 3/9 [06:09<12:13, 122.19s/it]\u001b[A\n",
      "Iteration:  44%|██████████████▏                 | 4/9 [08:27<10:34, 126.86s/it]\u001b[A\n",
      "Iteration:  56%|█████████████████▊              | 5/9 [10:38<08:32, 128.16s/it]\u001b[A\n",
      "Iteration:  67%|█████████████████████▎          | 6/9 [12:54<06:31, 130.47s/it]\u001b[A\n",
      "Iteration:  78%|████████████████████████▉       | 7/9 [15:07<04:22, 131.27s/it]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▍   | 8/9 [17:17<02:10, 130.84s/it]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 9/9 [18:42<00:00, 124.68s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                        | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  12%|████                            | 1/8 [00:40<04:43, 40.45s/it]\u001b[A\n",
      "Evaluating:  25%|████████                        | 2/8 [01:21<04:03, 40.53s/it]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 3/8 [02:01<03:22, 40.55s/it]\u001b[A\n",
      "Evaluating:  50%|████████████████                | 4/8 [02:42<02:41, 40.46s/it]\u001b[A\n",
      "Evaluating:  62%|████████████████████            | 5/8 [03:20<01:59, 39.87s/it]\u001b[A\n",
      "Evaluating:  75%|████████████████████████        | 6/8 [03:59<01:19, 39.74s/it]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████    | 7/8 [04:40<00:39, 39.93s/it]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 8/8 [05:08<00:00, 38.57s/it]\u001b[A\n",
      "Epoch:   9%|██▉                             | 2/22 [47:35<7:55:30, 1426.52s/it]\n",
      "Iteration:   0%|                                         | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.6204676330089569, 'accuracy': 0.6747967479674797, 'f1_score': 0.7085068411659727, 'roc_auc': 0.7506313131313131}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███▌                            | 1/9 [01:59<15:56, 119.58s/it]\u001b[A\n",
      "Iteration:  22%|███████                         | 2/9 [04:03<14:05, 120.80s/it]\u001b[A\n",
      "Iteration:  33%|██████████▋                     | 3/9 [06:11<12:17, 122.86s/it]\u001b[A\n",
      "Iteration:  44%|██████████████▏                 | 4/9 [08:28<10:34, 126.97s/it]\u001b[A\n",
      "Iteration:  56%|█████████████████▊              | 5/9 [10:26<08:18, 124.55s/it]\u001b[A\n",
      "Iteration:  67%|█████████████████████▎          | 6/9 [12:23<06:06, 122.17s/it]\u001b[A\n",
      "Iteration:  78%|████████████████████████▉       | 7/9 [14:29<04:06, 123.15s/it]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▍   | 8/9 [16:37<02:04, 124.68s/it]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 9/9 [18:01<00:00, 120.16s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                        | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  12%|████                            | 1/8 [00:39<04:39, 39.88s/it]\u001b[A\n",
      "Evaluating:  25%|████████                        | 2/8 [01:20<03:59, 39.97s/it]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 3/8 [02:00<03:21, 40.22s/it]\u001b[A\n",
      "Evaluating:  50%|████████████████                | 4/8 [02:41<02:41, 40.27s/it]\u001b[A\n",
      "Evaluating:  62%|████████████████████            | 5/8 [03:21<02:01, 40.38s/it]\u001b[A\n",
      "Evaluating:  75%|████████████████████████        | 6/8 [04:02<01:20, 40.49s/it]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████    | 7/8 [04:43<00:40, 40.52s/it]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 8/8 [05:11<00:00, 38.97s/it]\u001b[A\n",
      "Epoch:  14%|████                          | 3/22 [1:10:50<7:28:40, 1416.89s/it]\n",
      "Iteration:   0%|                                         | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.5123746395111084, 'accuracy': 0.7886178861788617, 'f1_score': 0.8057491289198606, 'roc_auc': 0.7897727272727272}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███▌                            | 1/9 [01:58<15:50, 118.79s/it]\u001b[A\n",
      "Iteration:  22%|███████                         | 2/9 [03:55<13:45, 117.99s/it]\u001b[A\n",
      "Iteration:  33%|██████████▋                     | 3/9 [06:02<12:03, 120.66s/it]\u001b[A\n",
      "Iteration:  44%|██████████████▏                 | 4/9 [08:04<10:06, 121.26s/it]\u001b[A\n",
      "Iteration:  56%|█████████████████▊              | 5/9 [10:05<08:04, 121.15s/it]\u001b[A\n",
      "Iteration:  67%|█████████████████████▎          | 6/9 [11:57<05:54, 118.25s/it]\u001b[A\n",
      "Iteration:  78%|████████████████████████▉       | 7/9 [13:50<03:53, 116.74s/it]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▍   | 8/9 [15:39<01:54, 114.42s/it]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 9/9 [17:04<00:00, 113.82s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                        | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  12%|████                            | 1/8 [00:38<04:32, 38.87s/it]\u001b[A\n",
      "Evaluating:  25%|████████                        | 2/8 [01:18<03:53, 38.96s/it]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 3/8 [01:56<03:14, 38.81s/it]\u001b[A\n",
      "Evaluating:  50%|████████████████                | 4/8 [02:36<02:36, 39.18s/it]\u001b[A\n",
      "Evaluating:  62%|████████████████████            | 5/8 [03:19<02:00, 40.26s/it]\u001b[A\n",
      "Evaluating:  75%|████████████████████████        | 6/8 [03:59<01:20, 40.24s/it]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████    | 7/8 [04:39<00:40, 40.24s/it]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 8/8 [05:08<00:00, 38.53s/it]\u001b[A\n",
      "Epoch:  18%|█████▍                        | 4/22 [1:33:05<6:57:44, 1392.49s/it]\n",
      "Iteration:   0%|                                         | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.611476581543684, 'accuracy': 0.6747967479674797, 'f1_score': 0.7085068411659727, 'roc_auc': 0.7506313131313131}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███▌                            | 1/9 [01:48<14:31, 108.89s/it]\u001b[A\n",
      "Iteration:  22%|███████                         | 2/9 [03:45<12:57, 111.07s/it]\u001b[A\n",
      "Iteration:  33%|██████████▋                     | 3/9 [05:42<11:17, 112.90s/it]\u001b[A\n",
      "Iteration:  44%|██████████████▏                 | 4/9 [07:34<09:23, 112.65s/it]\u001b[A\n",
      "Iteration:  56%|█████████████████▊              | 5/9 [09:26<07:29, 112.41s/it]\u001b[A\n",
      "Iteration:  67%|█████████████████████▎          | 6/9 [11:34<05:50, 116.98s/it]\u001b[A\n",
      "Iteration:  78%|████████████████████████▉       | 7/9 [13:25<03:50, 115.35s/it]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▍   | 8/9 [15:17<01:54, 114.44s/it]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 9/9 [16:39<00:00, 111.07s/it]\u001b[A\n",
      "\n",
      "Evaluating:   0%|                                        | 0/8 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:  12%|████                            | 1/8 [00:40<04:43, 40.49s/it]\u001b[A\n",
      "Evaluating:  25%|████████                        | 2/8 [01:21<04:03, 40.62s/it]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 3/8 [02:02<03:23, 40.65s/it]\u001b[A\n",
      "Evaluating:  50%|████████████████                | 4/8 [02:40<02:39, 39.96s/it]\u001b[A\n",
      "Evaluating:  62%|████████████████████            | 5/8 [03:20<01:59, 39.98s/it]\u001b[A\n",
      "Evaluating:  75%|████████████████████████        | 6/8 [04:00<01:20, 40.07s/it]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████    | 7/8 [04:40<00:40, 40.06s/it]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 8/8 [05:08<00:00, 38.58s/it]\u001b[A\n",
      "Epoch:  23%|██████▊                       | 5/22 [1:54:55<6:27:27, 1367.48s/it]\n",
      "Iteration:   0%|                                         | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.4500096905976534, 'accuracy': 0.7804878048780488, 'f1_score': 0.7999625797975648, 'roc_auc': 0.8005050505050506}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███▌                            | 1/9 [01:51<14:53, 111.71s/it]\u001b[A\n",
      "Iteration:  22%|███████                         | 2/9 [03:44<13:03, 111.99s/it]\u001b[A\n",
      "Iteration:  33%|██████████▋                     | 3/9 [05:37<11:14, 112.38s/it]\u001b[A\n",
      "Iteration:  44%|██████████████▏                 | 4/9 [07:31<09:23, 112.69s/it]\u001b[A\n",
      "Iteration:  56%|█████████████████▊              | 5/9 [09:30<07:38, 114.53s/it]\u001b[A\n",
      "Iteration:  67%|█████████████████████▎          | 6/9 [11:19<05:38, 112.83s/it]\u001b[A\n",
      "Iteration:  78%|████████████████████████▉       | 7/9 [13:10<03:44, 112.46s/it]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▍   | 8/9 [15:01<01:51, 111.85s/it]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 9/9 [16:20<00:00, 108.90s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                        | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  12%|████                            | 1/8 [00:38<04:28, 38.37s/it]\u001b[A\n",
      "Evaluating:  25%|████████                        | 2/8 [01:16<03:50, 38.35s/it]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 3/8 [01:55<03:12, 38.40s/it]\u001b[A\n",
      "Evaluating:  50%|████████████████                | 4/8 [02:34<02:35, 38.81s/it]\u001b[A\n",
      "Evaluating:  62%|████████████████████            | 5/8 [03:13<01:56, 38.75s/it]\u001b[A\n",
      "Evaluating:  75%|████████████████████████        | 6/8 [03:52<01:17, 38.77s/it]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████    | 7/8 [04:30<00:38, 38.71s/it]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 8/8 [04:57<00:00, 37.18s/it]\u001b[A\n",
      "Epoch:  27%|████████▏                     | 6/22 [2:16:15<5:57:42, 1341.42s/it]\n",
      "Iteration:   0%|                                         | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.417155088391155, 'accuracy': 0.8617886178861789, 'f1_score': 0.8665177198257465, 'roc_auc': 0.8194444444444444}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███▌                            | 1/9 [01:49<14:32, 109.05s/it]\u001b[A\n",
      "Iteration:  22%|███████                         | 2/9 [03:40<12:48, 109.80s/it]\u001b[A\n",
      "Iteration:  33%|██████████▋                     | 3/9 [05:31<11:00, 110.04s/it]\u001b[A\n",
      "Iteration:  44%|██████████████▏                 | 4/9 [07:18<09:05, 109.13s/it]\u001b[A\n",
      "Iteration:  56%|█████████████████▊              | 5/9 [09:12<07:23, 110.78s/it]\u001b[A\n",
      "Iteration:  67%|█████████████████████▎          | 6/9 [11:03<05:32, 110.73s/it]\u001b[A\n",
      "Iteration:  78%|████████████████████████▉       | 7/9 [12:54<03:41, 110.83s/it]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▍   | 8/9 [14:45<01:50, 110.73s/it]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 9/9 [16:11<00:00, 107.90s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                        | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  12%|████                            | 1/8 [00:39<04:38, 39.81s/it]\u001b[A\n",
      "Evaluating:  25%|████████                        | 2/8 [01:20<03:59, 39.95s/it]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 3/8 [02:00<03:19, 39.98s/it]\u001b[A\n",
      "Evaluating:  50%|████████████████                | 4/8 [02:40<02:40, 40.12s/it]\u001b[A\n",
      "Evaluating:  62%|████████████████████            | 5/8 [03:20<02:00, 40.18s/it]\u001b[A\n",
      "Evaluating:  75%|████████████████████████        | 6/8 [04:00<01:20, 40.12s/it]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████    | 7/8 [04:41<00:40, 40.19s/it]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 8/8 [05:09<00:00, 38.70s/it]\u001b[A\n",
      "Epoch:  32%|█████████▌                    | 7/22 [2:37:39<5:31:01, 1324.11s/it]\n",
      "Iteration:   0%|                                         | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.5676400037482381, 'accuracy': 0.7886178861788617, 'f1_score': 0.8068736141906874, 'roc_auc': 0.8055555555555555}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███▌                            | 1/9 [01:54<15:12, 114.10s/it]\u001b[A\n",
      "Iteration:  22%|███████                         | 2/9 [03:53<13:28, 115.56s/it]\u001b[A\n",
      "Iteration:  33%|██████████▋                     | 3/9 [05:42<11:22, 113.81s/it]\u001b[A\n",
      "Iteration:  44%|██████████████▏                 | 4/9 [07:30<09:20, 112.09s/it]\u001b[A\n",
      "Iteration:  56%|█████████████████▊              | 5/9 [09:21<07:26, 111.64s/it]\u001b[A\n",
      "Iteration:  67%|█████████████████████▎          | 6/9 [11:12<05:33, 111.30s/it]\u001b[A\n",
      "Iteration:  78%|████████████████████████▉       | 7/9 [13:06<03:44, 112.35s/it]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▍   | 8/9 [14:53<01:50, 110.75s/it]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 9/9 [16:12<00:00, 108.10s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                        | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  12%|████                            | 1/8 [00:39<04:38, 39.76s/it]\u001b[A\n",
      "Evaluating:  25%|████████                        | 2/8 [01:17<03:55, 39.30s/it]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 3/8 [01:56<03:15, 39.09s/it]\u001b[A\n",
      "Evaluating:  50%|████████████████                | 4/8 [02:34<02:35, 38.87s/it]\u001b[A\n",
      "Evaluating:  62%|████████████████████            | 5/8 [03:13<01:56, 38.73s/it]\u001b[A\n",
      "Evaluating:  75%|████████████████████████        | 6/8 [03:51<01:17, 38.66s/it]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████    | 7/8 [04:32<00:39, 39.11s/it]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 8/8 [04:59<00:00, 37.48s/it]\u001b[A\n",
      "Epoch:  36%|██████████▉                   | 8/22 [2:58:56<5:05:40, 1310.07s/it]\n",
      "Iteration:   0%|                                         | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.5474206642247736, 'accuracy': 0.8455284552845529, 'f1_score': 0.852527832274991, 'roc_auc': 0.8093434343434344}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███▌                            | 1/9 [01:47<14:19, 107.49s/it]\u001b[A\n",
      "Iteration:  22%|███████                         | 2/9 [03:39<12:41, 108.75s/it]\u001b[A\n",
      "Iteration:  33%|██████████▋                     | 3/9 [05:30<10:57, 109.53s/it]\u001b[A\n",
      "Iteration:  44%|██████████████▏                 | 4/9 [07:22<09:11, 110.24s/it]\u001b[A\n",
      "Iteration:  56%|█████████████████▊              | 5/9 [09:14<07:22, 110.74s/it]\u001b[A\n",
      "Iteration:  67%|█████████████████████▎          | 6/9 [11:06<05:33, 111.12s/it]\u001b[A\n",
      "Iteration:  78%|████████████████████████▉       | 7/9 [12:57<03:41, 110.88s/it]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▍   | 8/9 [14:48<01:51, 111.06s/it]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 9/9 [16:14<00:00, 108.32s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                        | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  12%|████                            | 1/8 [00:40<04:40, 40.10s/it]\u001b[A\n",
      "Evaluating:  25%|████████                        | 2/8 [01:20<04:01, 40.23s/it]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 3/8 [02:01<03:21, 40.34s/it]\u001b[A\n",
      "Evaluating:  50%|████████████████                | 4/8 [02:41<02:41, 40.34s/it]\u001b[A\n",
      "Evaluating:  62%|████████████████████            | 5/8 [03:20<01:59, 39.94s/it]\u001b[A\n",
      "Evaluating:  75%|████████████████████████        | 6/8 [04:01<01:20, 40.13s/it]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████    | 7/8 [04:41<00:40, 40.30s/it]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 8/8 [05:10<00:00, 38.75s/it]\u001b[A\n",
      "Epoch:  41%|████████████▎                 | 9/22 [3:20:23<4:42:21, 1303.16s/it]\n",
      "Iteration:   0%|                                         | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.5264310580678284, 'accuracy': 0.8780487804878049, 'f1_score': 0.8806974947577528, 'roc_auc': 0.8295454545454546}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███▌                            | 1/9 [01:52<15:02, 112.76s/it]\u001b[A\n",
      "Iteration:  22%|███████                         | 2/9 [03:42<13:02, 111.75s/it]\u001b[A\n",
      "Iteration:  33%|██████████▋                     | 3/9 [05:30<11:03, 110.61s/it]\u001b[A\n",
      "Iteration:  44%|██████████████▏                 | 4/9 [07:21<09:13, 110.73s/it]\u001b[A\n",
      "Iteration:  56%|█████████████████▊              | 5/9 [09:14<07:25, 111.48s/it]\u001b[A\n",
      "Iteration:  67%|█████████████████████▎          | 6/9 [11:05<05:34, 111.36s/it]\u001b[A\n",
      "Iteration:  78%|████████████████████████▉       | 7/9 [13:01<03:45, 112.74s/it]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▍   | 8/9 [14:56<01:53, 113.28s/it]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 9/9 [16:16<00:00, 108.53s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                        | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  12%|████                            | 1/8 [00:38<04:29, 38.48s/it]\u001b[A\n",
      "Evaluating:  25%|████████                        | 2/8 [01:16<03:50, 38.47s/it]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 3/8 [01:55<03:12, 38.42s/it]\u001b[A\n",
      "Evaluating:  50%|████████████████                | 4/8 [02:33<02:33, 38.42s/it]\u001b[A\n",
      "Evaluating:  62%|████████████████████            | 5/8 [03:12<01:55, 38.44s/it]\u001b[A\n",
      "Evaluating:  75%|████████████████████████        | 6/8 [03:50<01:16, 38.40s/it]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████    | 7/8 [04:28<00:38, 38.36s/it]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 8/8 [04:55<00:00, 36.93s/it]\u001b[A\n",
      "Epoch:  45%|█████████████▏               | 10/22 [3:41:39<4:19:00, 1295.02s/it]\n",
      "Iteration:   0%|                                         | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.5962619823403656, 'accuracy': 0.8699186991869918, 'f1_score': 0.8751129177958449, 'roc_auc': 0.8402777777777777}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███▌                            | 1/9 [01:47<14:13, 106.73s/it]\u001b[A\n",
      "Iteration:  22%|███████                         | 2/9 [03:57<12:58, 111.24s/it]\u001b[A\n",
      "Iteration:  33%|██████████▋                     | 3/9 [05:50<11:26, 114.35s/it]\u001b[A\n",
      "Iteration:  44%|██████████████▏                 | 4/9 [07:36<09:20, 112.08s/it]\u001b[A\n",
      "Iteration:  56%|█████████████████▊              | 5/9 [09:25<07:24, 111.11s/it]\u001b[A\n",
      "Iteration:  67%|█████████████████████▎          | 6/9 [11:17<05:33, 111.32s/it]\u001b[A\n",
      "Iteration:  78%|████████████████████████▉       | 7/9 [13:08<03:42, 111.28s/it]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▍   | 8/9 [15:02<01:52, 112.15s/it]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 9/9 [16:27<00:00, 109.71s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                        | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  12%|████                            | 1/8 [00:39<04:37, 39.61s/it]\u001b[A\n",
      "Evaluating:  25%|████████                        | 2/8 [01:19<03:57, 39.61s/it]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 3/8 [01:58<03:17, 39.57s/it]\u001b[A\n",
      "Evaluating:  50%|████████████████                | 4/8 [02:38<02:38, 39.69s/it]\u001b[A\n",
      "Evaluating:  62%|████████████████████            | 5/8 [03:18<01:59, 39.70s/it]\u001b[A\n",
      "Evaluating:  75%|████████████████████████        | 6/8 [03:57<01:18, 39.45s/it]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████    | 7/8 [04:37<00:39, 39.72s/it]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 8/8 [05:05<00:00, 38.21s/it]\u001b[A\n",
      "Epoch:  50%|██████████████▌              | 11/22 [4:03:15<3:57:28, 1295.35s/it]\n",
      "Iteration:   0%|                                         | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.5117664849385619, 'accuracy': 0.8943089430894309, 'f1_score': 0.8951191718485091, 'roc_auc': 0.8396464646464646}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███▌                            | 1/9 [01:48<14:26, 108.27s/it]\u001b[A\n",
      "Iteration:  22%|███████                         | 2/9 [03:40<12:45, 109.33s/it]\u001b[A\n",
      "Iteration:  33%|██████████▋                     | 3/9 [05:41<11:16, 112.82s/it]\u001b[A\n",
      "Iteration:  44%|██████████████▏                 | 4/9 [07:30<09:19, 111.84s/it]\u001b[A\n",
      "Iteration:  56%|█████████████████▊              | 5/9 [09:22<07:26, 111.72s/it]\u001b[A\n",
      "Iteration:  67%|█████████████████████▎          | 6/9 [11:14<05:36, 112.03s/it]\u001b[A\n",
      "Iteration:  78%|████████████████████████▉       | 7/9 [13:09<03:45, 112.82s/it]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▍   | 8/9 [15:02<01:52, 112.85s/it]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 9/9 [16:27<00:00, 109.78s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                        | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  12%|████                            | 1/8 [00:40<04:40, 40.06s/it]\u001b[A\n",
      "Evaluating:  25%|████████                        | 2/8 [01:20<04:01, 40.25s/it]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 3/8 [02:00<03:19, 39.97s/it]\u001b[A\n",
      "Evaluating:  50%|████████████████                | 4/8 [02:38<02:37, 39.45s/it]\u001b[A\n",
      "Evaluating:  62%|████████████████████            | 5/8 [03:16<01:57, 39.07s/it]\u001b[A\n",
      "Evaluating:  75%|████████████████████████        | 6/8 [03:55<01:17, 38.92s/it]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████    | 7/8 [04:33<00:38, 38.75s/it]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 8/8 [04:59<00:00, 37.47s/it]\u001b[A\n",
      "Epoch:  55%|███████████████▊             | 12/22 [4:24:46<3:35:38, 1293.89s/it]\n",
      "Iteration:   0%|                                         | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.5787388291209936, 'accuracy': 0.8699186991869918, 'f1_score': 0.8751129177958449, 'roc_auc': 0.8402777777777777}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███▌                            | 1/9 [01:46<14:12, 106.55s/it]\u001b[A\n",
      "Iteration:  22%|███████                         | 2/9 [03:37<12:34, 107.81s/it]\u001b[A\n",
      "Iteration:  33%|██████████▋                     | 3/9 [05:27<10:50, 108.43s/it]\u001b[A\n",
      "Iteration:  44%|██████████████▏                 | 4/9 [07:18<09:06, 109.24s/it]\u001b[A\n",
      "Iteration:  56%|█████████████████▊              | 5/9 [09:07<07:17, 109.28s/it]\u001b[A\n",
      "Iteration:  67%|█████████████████████▎          | 6/9 [11:06<05:34, 111.35s/it]\u001b[A\n",
      "Iteration:  78%|████████████████████████▉       | 7/9 [13:05<03:48, 114.33s/it]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▍   | 8/9 [14:55<01:53, 113.06s/it]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 9/9 [16:18<00:00, 108.67s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                        | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  12%|████                            | 1/8 [00:40<04:43, 40.56s/it]\u001b[A\n",
      "Evaluating:  25%|████████                        | 2/8 [01:22<04:05, 40.84s/it]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 3/8 [02:01<03:21, 40.34s/it]\u001b[A\n",
      "Evaluating:  50%|████████████████                | 4/8 [02:41<02:40, 40.23s/it]\u001b[A\n",
      "Evaluating:  62%|████████████████████            | 5/8 [03:21<02:00, 40.18s/it]\u001b[A\n",
      "Evaluating:  75%|████████████████████████        | 6/8 [04:01<01:20, 40.22s/it]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████    | 7/8 [04:42<00:40, 40.28s/it]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 8/8 [05:10<00:00, 38.78s/it]\u001b[A\n",
      "Epoch:  59%|█████████████████▏           | 13/22 [4:46:18<3:14:00, 1293.36s/it]\n",
      "Iteration:   0%|                                         | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.7072811368852854, 'accuracy': 0.8292682926829268, 'f1_score': 0.8425962948154072, 'roc_auc': 0.8465909090909092}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███▌                            | 1/9 [01:49<14:36, 109.59s/it]\u001b[A\n",
      "Iteration:  22%|███████                         | 2/9 [03:41<12:50, 110.14s/it]\u001b[A\n",
      "Iteration:  33%|██████████▋                     | 3/9 [05:32<11:02, 110.41s/it]\u001b[A\n",
      "Iteration:  44%|██████████████▏                 | 4/9 [07:23<09:13, 110.72s/it]\u001b[A\n",
      "Iteration:  56%|█████████████████▊              | 5/9 [09:12<07:21, 110.26s/it]\u001b[A\n",
      "Iteration:  67%|█████████████████████▎          | 6/9 [11:04<05:31, 110.57s/it]\u001b[A\n",
      "Iteration:  78%|████████████████████████▉       | 7/9 [12:55<03:41, 110.76s/it]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▍   | 8/9 [14:47<01:51, 111.19s/it]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 9/9 [16:12<00:00, 108.09s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                        | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  12%|████                            | 1/8 [00:39<04:37, 39.64s/it]\u001b[A\n",
      "Evaluating:  25%|████████                        | 2/8 [01:19<03:58, 39.79s/it]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 3/8 [01:59<03:19, 39.91s/it]\u001b[A\n",
      "Evaluating:  50%|████████████████                | 4/8 [02:38<02:38, 39.58s/it]\u001b[A\n",
      "Evaluating:  62%|████████████████████            | 5/8 [03:18<01:59, 39.71s/it]\u001b[A\n",
      "Evaluating:  75%|████████████████████████        | 6/8 [03:59<01:19, 39.94s/it]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████    | 7/8 [04:38<00:39, 39.70s/it]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 8/8 [05:06<00:00, 38.34s/it]\u001b[A\n",
      "Epoch:  64%|██████████████████▍          | 14/22 [5:07:38<2:51:55, 1289.49s/it]\n",
      "Iteration:   0%|                                         | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.553994054440409, 'accuracy': 0.8699186991869918, 'f1_score': 0.8735807818030599, 'roc_auc': 0.8244949494949495}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███▌                            | 1/9 [01:54<15:15, 114.39s/it]\u001b[A\n",
      "Iteration:  22%|███████                         | 2/9 [03:44<13:10, 112.99s/it]\u001b[A\n",
      "Iteration:  33%|██████████▋                     | 3/9 [05:35<11:15, 112.62s/it]\u001b[A\n",
      "Iteration:  44%|██████████████▏                 | 4/9 [07:28<09:22, 112.56s/it]\u001b[A\n",
      "Iteration:  56%|█████████████████▊              | 5/9 [09:15<07:23, 110.86s/it]\u001b[A\n",
      "Iteration:  67%|█████████████████████▎          | 6/9 [11:11<05:37, 112.60s/it]\u001b[A\n",
      "Iteration:  78%|████████████████████████▉       | 7/9 [12:58<03:41, 110.95s/it]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▍   | 8/9 [14:59<01:53, 113.84s/it]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 9/9 [16:19<00:00, 108.85s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                        | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  12%|████                            | 1/8 [00:39<04:38, 39.80s/it]\u001b[A\n",
      "Evaluating:  25%|████████                        | 2/8 [01:19<03:58, 39.79s/it]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 3/8 [01:57<03:16, 39.28s/it]\u001b[A\n",
      "Evaluating:  50%|████████████████                | 4/8 [02:36<02:36, 39.01s/it]\u001b[A\n",
      "Evaluating:  62%|████████████████████            | 5/8 [03:15<01:57, 39.03s/it]\u001b[A\n",
      "Evaluating:  75%|████████████████████████        | 6/8 [03:54<01:18, 39.26s/it]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████    | 7/8 [04:33<00:39, 39.01s/it]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 8/8 [04:59<00:00, 37.47s/it]\u001b[A\n",
      "Epoch:  68%|███████████████████▊         | 15/22 [5:29:05<2:30:19, 1288.50s/it]\n",
      "Iteration:   0%|                                         | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.5448995255865157, 'accuracy': 0.8780487804878049, 'f1_score': 0.8806974947577528, 'roc_auc': 0.8295454545454546}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███▌                            | 1/9 [01:46<14:14, 106.80s/it]\u001b[A\n",
      "Iteration:  22%|███████                         | 2/9 [03:37<12:36, 108.03s/it]\u001b[A\n",
      "Iteration:  33%|██████████▋                     | 3/9 [05:35<11:05, 110.98s/it]\u001b[A\n",
      "Iteration:  44%|██████████████▏                 | 4/9 [07:29<09:18, 111.65s/it]\u001b[A\n",
      "Iteration:  56%|█████████████████▊              | 5/9 [09:25<07:32, 113.19s/it]\u001b[A\n",
      "Iteration:  67%|█████████████████████▎          | 6/9 [11:12<05:34, 111.43s/it]\u001b[A\n",
      "Iteration:  78%|████████████████████████▉       | 7/9 [13:02<03:41, 110.92s/it]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▍   | 8/9 [14:52<01:50, 110.72s/it]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 9/9 [16:17<00:00, 108.65s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                        | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  12%|████                            | 1/8 [00:39<04:38, 39.80s/it]\u001b[A\n",
      "Evaluating:  25%|████████                        | 2/8 [01:19<03:59, 39.88s/it]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 3/8 [02:00<03:19, 40.00s/it]\u001b[A\n",
      "Evaluating:  50%|████████████████                | 4/8 [02:38<02:38, 39.59s/it]\u001b[A\n",
      "Evaluating:  62%|████████████████████            | 5/8 [03:19<01:59, 39.84s/it]\u001b[A\n",
      "Evaluating:  75%|████████████████████████        | 6/8 [03:58<01:19, 39.55s/it]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████    | 7/8 [04:36<00:39, 39.16s/it]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 8/8 [05:02<00:00, 37.83s/it]\u001b[A\n",
      "Epoch:  73%|█████████████████████        | 16/22 [5:50:28<2:08:42, 1287.03s/it]\n",
      "Iteration:   0%|                                         | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.5458987597376108, 'accuracy': 0.8780487804878049, 'f1_score': 0.8806974947577528, 'roc_auc': 0.8295454545454546}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███▌                            | 1/9 [01:49<14:36, 109.55s/it]\u001b[A\n",
      "Iteration:  22%|███████                         | 2/9 [03:41<12:52, 110.33s/it]\u001b[A\n",
      "Iteration:  33%|██████████▋                     | 3/9 [05:33<11:04, 110.68s/it]\u001b[A\n",
      "Iteration:  44%|██████████████▏                 | 4/9 [07:25<09:16, 111.20s/it]\u001b[A\n",
      "Iteration:  56%|█████████████████▊              | 5/9 [09:19<07:27, 111.92s/it]\u001b[A\n",
      "Iteration:  67%|█████████████████████▎          | 6/9 [11:10<05:35, 111.79s/it]\u001b[A\n",
      "Iteration:  78%|████████████████████████▉       | 7/9 [13:02<03:43, 111.82s/it]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▍   | 8/9 [15:03<01:54, 114.43s/it]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 9/9 [16:22<00:00, 109.22s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                        | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  12%|████                            | 1/8 [00:38<04:26, 38.06s/it]\u001b[A\n",
      "Evaluating:  25%|████████                        | 2/8 [01:16<03:48, 38.06s/it]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 3/8 [01:54<03:10, 38.11s/it]\u001b[A\n",
      "Evaluating:  50%|████████████████                | 4/8 [02:32<02:32, 38.14s/it]\u001b[A\n",
      "Evaluating:  62%|████████████████████            | 5/8 [03:10<01:54, 38.16s/it]\u001b[A\n",
      "Evaluating:  75%|████████████████████████        | 6/8 [03:49<01:16, 38.26s/it]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████    | 7/8 [04:27<00:38, 38.25s/it]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 8/8 [04:53<00:00, 36.73s/it]\u001b[A\n",
      "Epoch:  77%|██████████████████████▍      | 17/22 [6:11:47<1:47:03, 1284.65s/it]\n",
      "Iteration:   0%|                                         | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.5674653183668852, 'accuracy': 0.8780487804878049, 'f1_score': 0.8822215174933057, 'roc_auc': 0.8453282828282828}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███▌                            | 1/9 [01:50<14:46, 110.78s/it]\u001b[A\n",
      "Iteration:  22%|███████                         | 2/9 [03:42<12:55, 110.73s/it]\u001b[A\n",
      "Iteration:  33%|██████████▋                     | 3/9 [05:37<11:12, 112.14s/it]\u001b[A\n",
      "Iteration:  44%|██████████████▏                 | 4/9 [07:24<09:13, 110.72s/it]\u001b[A\n",
      "Iteration:  56%|█████████████████▊              | 5/9 [09:15<07:23, 110.77s/it]\u001b[A\n",
      "Iteration:  67%|█████████████████████▎          | 6/9 [11:08<05:34, 111.61s/it]\u001b[A\n",
      "Iteration:  78%|████████████████████████▉       | 7/9 [12:56<03:40, 110.48s/it]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▍   | 8/9 [14:44<01:49, 109.76s/it]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 9/9 [16:03<00:00, 107.08s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                        | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  12%|████                            | 1/8 [00:38<04:27, 38.21s/it]\u001b[A\n",
      "Evaluating:  25%|████████                        | 2/8 [01:16<03:48, 38.10s/it]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 3/8 [01:56<03:13, 38.69s/it]\u001b[A\n",
      "Evaluating:  50%|████████████████                | 4/8 [02:34<02:34, 38.58s/it]\u001b[A\n",
      "Evaluating:  62%|████████████████████            | 5/8 [03:12<01:55, 38.53s/it]\u001b[A\n",
      "Evaluating:  75%|████████████████████████        | 6/8 [03:54<01:19, 39.56s/it]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████    | 7/8 [04:33<00:39, 39.19s/it]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 8/8 [04:59<00:00, 37.43s/it]\u001b[A\n",
      "Epoch:  82%|███████████████████████▋     | 18/22 [6:32:57<1:25:20, 1280.22s/it]\n",
      "Iteration:   0%|                                         | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.584462080616504, 'accuracy': 0.8780487804878049, 'f1_score': 0.8822215174933057, 'roc_auc': 0.8453282828282828}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███▌                            | 1/9 [01:48<14:30, 108.86s/it]\u001b[A\n",
      "Iteration:  22%|███████                         | 2/9 [03:40<12:46, 109.56s/it]\u001b[A\n",
      "Iteration:  33%|██████████▋                     | 3/9 [05:41<11:17, 112.95s/it]\u001b[A\n",
      "Iteration:  44%|██████████████▏                 | 4/9 [07:33<09:23, 112.79s/it]\u001b[A\n",
      "Iteration:  56%|█████████████████▊              | 5/9 [09:25<07:30, 112.72s/it]\u001b[A\n",
      "Iteration:  67%|█████████████████████▎          | 6/9 [11:18<05:37, 112.57s/it]\u001b[A\n",
      "Iteration:  78%|████████████████████████▉       | 7/9 [13:08<03:43, 111.81s/it]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▍   | 8/9 [14:59<01:51, 111.73s/it]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 9/9 [16:22<00:00, 109.18s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                        | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  12%|████                            | 1/8 [00:38<04:29, 38.48s/it]\u001b[A\n",
      "Evaluating:  25%|████████                        | 2/8 [01:18<03:53, 38.84s/it]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 3/8 [01:57<03:14, 38.92s/it]\u001b[A\n",
      "Evaluating:  50%|████████████████                | 4/8 [02:36<02:36, 39.06s/it]\u001b[A\n",
      "Evaluating:  62%|████████████████████            | 5/8 [03:17<01:58, 39.48s/it]\u001b[A\n",
      "Evaluating:  75%|████████████████████████        | 6/8 [03:57<01:19, 39.75s/it]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████    | 7/8 [04:37<00:39, 39.89s/it]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 8/8 [05:04<00:00, 38.07s/it]\u001b[A\n",
      "Epoch:  86%|█████████████████████████    | 19/22 [6:54:27<1:04:09, 1283.06s/it]\n",
      "Iteration:   0%|                                         | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.5873709497973323, 'accuracy': 0.8780487804878049, 'f1_score': 0.8822215174933057, 'roc_auc': 0.8453282828282828}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███▌                            | 1/9 [01:51<14:51, 111.48s/it]\u001b[A\n",
      "Iteration:  22%|███████                         | 2/9 [03:43<13:02, 111.74s/it]\u001b[A\n",
      "Iteration:  33%|██████████▋                     | 3/9 [05:35<11:09, 111.59s/it]\u001b[A\n",
      "Iteration:  44%|██████████████▏                 | 4/9 [07:38<09:34, 114.96s/it]\u001b[A\n",
      "Iteration:  56%|█████████████████▊              | 5/9 [09:23<07:28, 112.15s/it]\u001b[A\n",
      "Iteration:  67%|█████████████████████▎          | 6/9 [11:19<05:38, 112.88s/it]\u001b[A\n",
      "Iteration:  78%|████████████████████████▉       | 7/9 [13:14<03:47, 113.90s/it]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▍   | 8/9 [15:03<01:52, 112.44s/it]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 9/9 [16:21<00:00, 109.08s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                        | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  12%|████                            | 1/8 [00:37<04:24, 37.86s/it]\u001b[A\n",
      "Evaluating:  25%|████████                        | 2/8 [01:15<03:47, 37.92s/it]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 3/8 [01:54<03:09, 37.97s/it]\u001b[A\n",
      "Evaluating:  50%|████████████████                | 4/8 [02:32<02:32, 38.03s/it]\u001b[A\n",
      "Evaluating:  62%|████████████████████            | 5/8 [03:11<01:55, 38.51s/it]\u001b[A\n",
      "Evaluating:  75%|████████████████████████        | 6/8 [03:50<01:17, 38.58s/it]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████    | 7/8 [04:29<00:38, 38.61s/it]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 8/8 [04:55<00:00, 36.95s/it]\u001b[A\n",
      "Epoch:  91%|████████████████████████████▏  | 20/22 [7:15:48<42:44, 1282.50s/it]\n",
      "Iteration:   0%|                                         | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.5836742650717497, 'accuracy': 0.8780487804878049, 'f1_score': 0.8822215174933057, 'roc_auc': 0.8453282828282828}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███▌                            | 1/9 [01:46<14:10, 106.35s/it]\u001b[A\n",
      "Iteration:  22%|███████                         | 2/9 [03:36<12:32, 107.48s/it]\u001b[A\n",
      "Iteration:  33%|██████████▋                     | 3/9 [05:38<11:09, 111.64s/it]\u001b[A\n",
      "Iteration:  44%|██████████████▏                 | 4/9 [07:29<09:17, 111.57s/it]\u001b[A\n",
      "Iteration:  56%|█████████████████▊              | 5/9 [09:33<07:41, 115.30s/it]\u001b[A\n",
      "Iteration:  67%|█████████████████████▎          | 6/9 [11:24<05:42, 114.11s/it]\u001b[A\n",
      "Iteration:  78%|████████████████████████▉       | 7/9 [13:17<03:47, 113.66s/it]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▍   | 8/9 [15:08<01:53, 113.04s/it]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 9/9 [16:36<00:00, 110.68s/it]\u001b[A\n",
      "\n",
      "Evaluating:   0%|                                        | 0/8 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:  12%|████                            | 1/8 [00:38<04:29, 38.56s/it]\u001b[A\n",
      "Evaluating:  25%|████████                        | 2/8 [01:16<03:50, 38.39s/it]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 3/8 [01:54<03:11, 38.31s/it]\u001b[A\n",
      "Evaluating:  50%|████████████████                | 4/8 [02:32<02:32, 38.21s/it]\u001b[A\n",
      "Evaluating:  62%|████████████████████            | 5/8 [03:10<01:54, 38.24s/it]\u001b[A\n",
      "Evaluating:  75%|████████████████████████        | 6/8 [03:48<01:16, 38.18s/it]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████    | 7/8 [04:27<00:38, 38.20s/it]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 8/8 [04:53<00:00, 36.70s/it]\u001b[A\n",
      "Epoch:  95%|█████████████████████████████▌ | 21/22 [7:37:18<21:24, 1284.84s/it]\n",
      "Iteration:   0%|                                         | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.5862396312877536, 'accuracy': 0.8780487804878049, 'f1_score': 0.8822215174933057, 'roc_auc': 0.8453282828282828}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|███▌                            | 1/9 [01:51<14:51, 111.44s/it]\u001b[A\n",
      "Iteration:  22%|███████                         | 2/9 [03:43<13:00, 111.49s/it]\u001b[A\n",
      "Iteration:  33%|██████████▋                     | 3/9 [05:33<11:07, 111.30s/it]\u001b[A\n",
      "Iteration:  44%|██████████████▏                 | 4/9 [07:29<09:22, 112.58s/it]\u001b[A\n",
      "Iteration:  56%|█████████████████▊              | 5/9 [09:19<07:26, 111.73s/it]\u001b[A\n",
      "Iteration:  67%|█████████████████████▎          | 6/9 [11:08<05:32, 111.00s/it]\u001b[A\n",
      "Iteration:  78%|████████████████████████▉       | 7/9 [12:58<03:41, 110.62s/it]\u001b[A\n",
      "Iteration:  89%|████████████████████████████▍   | 8/9 [14:48<01:50, 110.57s/it]\u001b[A\n",
      "Iteration: 100%|████████████████████████████████| 9/9 [16:14<00:00, 108.29s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====Evaluation====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|                                        | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  12%|████                            | 1/8 [00:40<04:41, 40.26s/it]\u001b[A\n",
      "Evaluating:  25%|████████                        | 2/8 [01:20<04:00, 40.13s/it]\u001b[A\n",
      "Evaluating:  38%|████████████                    | 3/8 [01:59<03:19, 39.93s/it]\u001b[A\n",
      "Evaluating:  50%|████████████████                | 4/8 [02:37<02:37, 39.39s/it]\u001b[A\n",
      "Evaluating:  62%|████████████████████            | 5/8 [03:16<01:57, 39.09s/it]\u001b[A\n",
      "Evaluating:  75%|████████████████████████        | 6/8 [03:54<01:17, 38.79s/it]\u001b[A\n",
      "Evaluating:  88%|████████████████████████████    | 7/8 [04:32<00:38, 38.68s/it]\u001b[A\n",
      "Evaluating: 100%|████████████████████████████████| 8/8 [04:58<00:00, 37.36s/it]\u001b[A\n",
      "Epoch: 100%|███████████████████████████████| 22/22 [7:58:36<00:00, 1305.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  {'loss': 0.5873853485099971, 'accuracy': 0.8780487804878049, 'f1_score': 0.8822215174933057, 'roc_auc': 0.8453282828282828}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main_model = RBERT_re(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predict_args(object):\n",
    "      def __init__(self,\n",
    "                   input_file = '../data/test_file.csv',\n",
    "                   output_file = 'sample_pred_out_multilingual.txt',\n",
    "                   model_dir = 'model/',\n",
    "                   model_name_or_path = 'bert-base-multilingual-cased',\n",
    "                   num_labels = 2,\n",
    "                   add_sep_token = True,\n",
    "                   dropout_rate = 0.1,\n",
    "                   max_seq_len = 384,\n",
    "                   batch_size = 16,\n",
    "                   no_cuda = True):\n",
    "  \n",
    "        super(Predict_args, self).__init__()\n",
    "        self.input_file = input_file\n",
    "        self.output_file = output_file\n",
    "        self.model_dir = model_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.no_cuda = no_cuda\n",
    "        self.model_name_or_path = model_name_or_path\n",
    "        self.add_sep_token = add_sep_token\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.num_labels = num_labels\n",
    "        return\n",
    "\n",
    "pred_config = Predict_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "with open('../data/test_label.csv', \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        examples.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
    "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-ac301803d770>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-37-fbf455e5a237>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(pred_config)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_tokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-fbf455e5a237>\u001b[0m in \u001b[0;36mload_saved_model\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRBERT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model/model_multilingual_1105.bin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   1032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m         \u001b[1;31m# Instantiate model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1034\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-ec4f50307d23>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config, args)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRBERT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Load pretrained bert\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config, add_pooling_layer)\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertEmbeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    843\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpooler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertPooler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0madd_pooling_layer\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBertLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     def forward(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBertLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     def forward(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_decoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"{self} should be used as a decoder model if cross attention is added\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrossattention\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertAttention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertIntermediate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertOutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_act\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mACT2FN\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_act\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, in_features, out_features, bias)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bias'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mreset_parameters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mfan_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\venv\\lib\\site-packages\\torch\\nn\\init.py\u001b[0m in \u001b[0;36mkaiming_uniform_\u001b[1;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3.0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstd\u001b[0m  \u001b[1;31m# Calculate uniform bounds from standard deviation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mbound\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prediction = predict(pred_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|████████████████████████████████| 5/5 [03:13<00:00, 38.67s/it]\n"
     ]
    }
   ],
   "source": [
    "prediction = evaluate(pred_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tr = []\n",
    "for i in prediction:\n",
    "    if i==1:\n",
    "        a = 0\n",
    "    if i==0:\n",
    "        a = 1\n",
    "    pred_tr.append(a)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_np = np.array(pred_tr)\n",
    "pred_np = np.reshape(pred_np,(74,1))\n",
    "y_true = np.array(y_true)\n",
    "y_true = np.reshape(y_true,(74,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8852813852813852"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true, pred_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9336310223266745"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true, pred_np, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_np = np.array(prediction)\n",
    "# y_true = np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = [0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
    "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
    "       0, 1, 0, 1, 1, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
